```python
# Read the content of Phase 1 documentation
with open('Documentacao_Tecnica_ETL_Fase1_v2.md', 'r', encoding='utf-8') as f:
    doc_phase1 = f.read()

# Read the content of Phase 2 documentation
with open('docs_fase_2.md', 'r', encoding='utf-8') as f:
    doc_phase2 = f.read()

print("Phase 1 Content Length:", len(doc_phase1))
print("Phase 2 Content Length:", len(doc_phase2))


```

```text
Phase 1 Content Length: 5614
Phase 2 Content Length: 7269


```

Com base na documenta√ß√£o anexada, preparei uma vers√£o unificada e bem estruturada para o `README.md` do seu projeto no GitHub.

O documento abaixo integra o fluxo completo, desde a limpeza bruta (Fase 1) at√© a intelig√™ncia artificial preditiva (Fase 2), mantendo o n√≠vel t√©cnico detalhado que voc√™ solicitou.

---

# üìò Manual T√©cnico Unificado: Pipeline de Auditoria em Compras P√∫blicas

**Projeto:** Minera√ß√£o e Auditoria de Cart√£o de Pagamento do Governo Federal (CPGF)
**Tecnologia:** Python 3.x + PySpark (MLlib & SQL)
**Vers√£o do Pipeline:** 2.0 (Consolidado: ETL + Machine Learning Supervisionado)

---

## 1. Vis√£o Geral e Arquitetura

Este projeto implementa um pipeline de dados completo ("End-to-End") para processar, higienizar e auditar despesas p√∫blicas. A solu√ß√£o foi desenhada para transformar arquivos governamentais despadronizados em intelig√™ncia audit√°vel, utilizando t√©cnicas de Big Data e Machine Learning para identificar anomalias de pre√ßos e desvios sem√¢nticos.

### Arquitetura do Pipeline

O fluxo √© dividido em duas grandes fases sequenciais:

1. **Fase 1 (ETL & Saneamento):** Foca na ingest√£o de arquivos `.xls/.xlsx` sujos, normaliza√ß√£o de schema e aplica√ß√£o de regras de neg√≥cio "Forenses" para criar uma camada de dados confi√°vel ("Gold").
2. **Fase 2 (Minera√ß√£o & Auditoria):** Aplica Intelig√™ncia Artificial (NLP e Clusteriza√ß√£o) sobre os dados limpos para detectar fraudes atrav√©s de uma abordagem h√≠brida (Estat√≠stica + Preditiva).

---

## 2. Fase 1: Extra√ß√£o, Transforma√ß√£o e Carga (ETL)

Nesta etapa, o objetivo √© garantir que os dados brutos sejam utiliz√°veis, resolvendo problemas de formata√ß√£o, caracteres ocultos e inconsist√™ncia de colunas ao longo dos anos.

### 2.1. Estrat√©gia de Mapeamento "Slugify"

Arquivos governamentais mudam de cabe√ßalho anualmente (ex: "Objeto da Aquisi√ß√£o", "MOTIVO", "Objeto Aquisicao").

* **Solu√ß√£o:** Implementa√ß√£o de um dicion√°rio baseado em *slugs*. O pipeline remove acentos, espa√ßos e converte para min√∫sculo antes de mapear para o schema final (ex: `objetodaaquisicao` ‚Üí `objeto_aquisicao`). Isso blinda o processo contra erros de digita√ß√£o na origem.

### 2.2. Limpeza "Blindada" (Regex Allowlist)

Limpeza agressiva para campos monet√°rios e textuais que frequentemente cont√™m caracteres invis√≠veis ou formata√ß√£o quebrada.

* **Valores Monet√°rios:** Utiliza Regex `[^0-9,-]` para remover tudo que n√£o seja n√∫mero ou v√≠rgula, corrigindo casos como `R$ 1.200,50` para `DoubleType`.
* **Texto:** Normaliza√ß√£o de acentos e remo√ß√£o de caracteres especiais via `regexp_replace`.

### 2.3. Regras de Neg√≥cio e Consolida√ß√£o

* **Filtro de "Linhas Fantasmas":** Remo√ß√£o autom√°tica de linhas em branco ou nulas que representavam at√© 47% de arquivos Excel antigos.
* **Recupera√ß√£o de Dados ("Salvar a Leroy Merlin"):** Registros com valor monet√°rio v√°lido mas sem descri√ß√£o (`objeto_aquisicao` vazio) s√£o preservados e marcados como "NAO INFORMADO", garantindo que o dinheiro gasto n√£o seja descartado da an√°lise.

**Sa√≠da da Fase 1:** Arquivo √∫nico `Consolidado_Final.parquet` (Particionado por Ano).

---

## 3. Fase 2: Minera√ß√£o de Dados e Auditoria Avan√ßada

A Fase 2 consome os dados consolidados e aplica modelos matem√°ticos para identificar sobrepre√ßo baseando-se em **sem√¢ntica** (o que √© o item) e **contexto** (em qual grupo ele se encaixa).

### 3.1. Processamento de Linguagem Natural (NLP)

Transforma√ß√£o de texto livre em tokens significativos para o modelo.

* **Stopwords Customizadas:** Remo√ß√£o de ~150 termos burocr√°ticos que n√£o descrevem o produto (ex: `necessidade`, `urgencia`, `vulto`, `solicitado`).
* **Filtros de Radical (SQL):** Remo√ß√£o de termos institucionais como `almox*` (almoxarifado) e `reemb*` (reembolso) para focar no objeto real da compra.

### 3.2. Vetoriza√ß√£o (Word2Vec)

Ensina o computador a entender contexto e sin√¥nimos, transformando palavras em vetores matem√°ticos de 50 dimens√µes.

* **Configura√ß√£o:** `minCount=5` ignora palavras raras (erros de digita√ß√£o) para limpar o ru√≠do.

### 3.3. Clusteriza√ß√£o (Bisecting K-Means)

Agrupamento n√£o-supervisionado para criar "gavetas" tem√°ticas de compara√ß√£o.

* **L√≥gica:** O algoritmo divide a base em **20 clusters** baseados em similaridade sem√¢ntica (Dist√¢ncia de Cosseno), separando, por exemplo, "Pe√ßas Automotivas" de "Material de Escrit√≥rio" automaticamente.

### 3.4. Metodologia de Detec√ß√£o H√≠brida (O "C√©rebro" da Auditoria)

Utilizamos duas abordagens simult√¢neas para reduzir falsos positivos:

1. **M√©todo Estat√≠stico Intra-Cluster (IQR):**
* Analisa o item em rela√ß√£o aos seus pares no mesmo cluster.
* **Gatilho:** Detecta itens que furam o teto do Boxplot ().


2. **M√©todo Preditivo Supervisionado (Random Forest):**
* Analisa o item em rela√ß√£o ao "conhecimento global" da base, prevendo quanto ele *deveria* custar baseado na descri√ß√£o.
* **Gatilho:** Pre√ßo Pago > 3x Pre√ßo Estimado pelo modelo.



### 3.5. Score de Risco e Enriquecimento

O pipeline cruza os resultados dos dois m√©todos para gerar um **Score de Risco** unificado. Apenas itens com `Score > 10` (alta gravidade) s√£o exportados para o relat√≥rio final, que √© enriquecido com dados cadastrais originais (CPF/CNPJ) para permitir a investiga√ß√£o.

---

## 4. Configura√ß√£o do Ambiente

O projeto foi configurado para execu√ß√£o local em ambiente Windows, simulando um cluster Spark.

* **Engine:** Spark Session com `spark-excel` (`com.crealytics:spark-excel_2.12:3.5.0_0.20.3`).
* **Recursos:** Otimizado com `spark.driver.memory = "4g"` e `spark.sql.shuffle.partitions = "8"`.
* **Fix de Rede:** Configura√ß√£o `spark.driver.bindAddress = "127.0.0.1"` para evitar erros de VPN/Wi-Fi.

---

## 5. Dicion√°rio de Artefatos (Sa√≠das)

Ao final da execu√ß√£o, os seguintes arquivos s√£o gerados na pasta do projeto:

| Arquivo | Fase Origem | Descri√ß√£o | Uso Principal |
| --- | --- | --- | --- |
| `Consolidado_Final` | Fase 1 | Dataset Parquet limpo e unificado. | Base para an√°lises de BI e input da Fase 2. |
| `relatorio_outliers_iqr.csv` | Fase 2 | Anomalias estat√≠sticas por cluster. | An√°lise de dispers√£o de pre√ßos dentro dos grupos. |
| `auditoria_ml_random_forest.csv` | Fase 2 | Discrep√¢ncias Texto vs. Pre√ßo. | Identificar itens caros mal classificados ou superfaturados. |
| **`AUDITORIA_COMPLETA_RASTREAVEL.csv`** | **Fase 2** | **Relat√≥rio Final Cruzado.** | **Lista de investiga√ß√£o forense com Score de Risco e dados de CPF/CNPJ.** |

---

## 6. Como Executar

1. **Entrada:** Coloque os arquivos `.xlsx` originais na pasta `dados/input/{ANO}/`.
2. **Fase 1:** Execute o notebook/script de ETL para gerar o `Consolidado_Final`.
3. **Fase 2:** Execute o notebook/script de Minera√ß√£o. Acompanhe os logs de calibra√ß√£o do Random Forest (RMSE).
4. **Resultado:** O arquivo `AUDITORIA_COMPLETA_RASTREAVEL.csv` estar√° dispon√≠vel na raiz do projeto. Abra-o no Excel (separador `;`, UTF-8) e ordene pela coluna `Score_Risco`.
