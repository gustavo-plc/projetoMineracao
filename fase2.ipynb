{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c21c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Fase 2: An√°lise Explorat√≥ria ---\n",
      "üìÇ Buscando base consolidada em: c:\\VSCode\\projetoMineracao\\dados\\Consolidado_Final\n",
      "‚úÖ Base carregada: 54196 registros.\n",
      "\n",
      "--- Saneamento da Base ---\n",
      "Total Bruto: 54196\n",
      "‚úÖ Total Real (√önicos): 12572\n",
      "üóëÔ∏è Lixo Removido: 41624\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# FASE 2: An√°lise Explorat√≥ria de Dados (EDA) e Minera√ß√£o (Completo)\n",
    "# Arquivo: analise_fase2.py\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Importa√ß√µes Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, size, lower, avg, stddev, abs as _abs, round as _round, max as _max, min as _min, count\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# --- 1. Configura√ß√£o de Ambiente (Windows) ---\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "print(\"--- Iniciando Fase 2: An√°lise Explorat√≥ria ---\")\n",
    "\n",
    "# --- 2. Inicializando Sess√£o Spark ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analise_Gastos_Fase2\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Otimiza√ß√£o Arrow\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# --- 3. Carregamento dos Dados ---\n",
    "BASE_DIR = os.path.join(os.getcwd(), \"dados\")\n",
    "input_path = os.path.join(BASE_DIR, \"Consolidado_Final\")\n",
    "\n",
    "print(f\"üìÇ Buscando base consolidada em: {input_path}\")\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"‚ùå ARQUIVO N√ÉO ENCONTRADO: {input_path}\")\n",
    "    sys.exit() # Encerra se n√£o achar o arquivo\n",
    "\n",
    "try:\n",
    "    df = spark.read.parquet(input_path)\n",
    "    df.cache() # Cache do dataset bruto\n",
    "    print(f\"‚úÖ Base carregada: {df.count()} registros.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro leitura: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CORRE√á√ÉO CR√çTICA: Remo√ß√£o de Duplicatas\n",
    "# ==============================================================================\n",
    "print(f\"\\n--- Saneamento da Base ---\")\n",
    "print(f\"Total Bruto: {df.count()}\")\n",
    "\n",
    "# Remove linhas onde Objeto, Valor e Favorecido s√£o id√™nticos\n",
    "# Isso elimina as repeti√ß√µes causadas pela fus√£o de c√©lulas no Excel\n",
    "df = df.dropDuplicates(['objeto_aquisicao', 'valor_transacao', 'nome_favorecido'])\n",
    "\n",
    "# For√ßa o rec√°lculo e cache na mem√≥ria\n",
    "df.cache()\n",
    "count_real = df.count()\n",
    "\n",
    "print(f\"‚úÖ Total Real (√önicos): {count_real}\")\n",
    "print(f\"üóëÔ∏è Lixo Removido: {54196 - count_real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f0b390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando NLP V13 (Removendo 'Devido', 'Realiza√ß√£o' e cia) ---\n",
      "‚úÖ NLP V13 conclu√≠do.\n",
      "+-----------------------------------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "|objeto_aquisicao                                                                               |words_filtered                                                   |\n",
      "+-----------------------------------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "|01 agua oxigenada  10v 1 litro  \\n01 detegente enzimatico 250ml \\n01 filme agfa periapical c150|[agua, oxigenada, detegente, enzimatico, filme, agfa, periapical]|\n",
      "|01 anel de vedacao para bacias sanitarias  com guia 1                                          |[anel, vedacao, bacias, sanitarias, guia]                        |\n",
      "|01 anel de vedacao para bacias sanitarias  com guia 1                                          |[anel, vedacao, bacias, sanitarias, guia]                        |\n",
      "|01 bateria recarregavel para telefone sem fio                                                  |[recarregavel, telefone, fio]                                    |\n",
      "|01 borracha p carimbo 04 copias de chave e 01 cadeado                                          |[borracha, carimbo, copias, chave, cadeado]                      |\n",
      "+-----------------------------------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 6 (V13): NLP - Remo√ß√£o de Conectivos e Termos de A√ß√£o\n",
    "# ==============================================================================\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, size, regexp_replace, expr\n",
    "\n",
    "print(\"--- Iniciando NLP V13 (Removendo 'Devido', 'Realiza√ß√£o' e cia) ---\")\n",
    "\n",
    "# 1. Limpeza de Caracteres\n",
    "# Como deve ficar (Seguro):\n",
    "df_clean_chars = df.withColumn(\"objeto_limpo\", regexp_replace(lower(col(\"objeto_aquisicao\")), r\"[^a-z]\", \" \"))\n",
    "\n",
    "# 2. Stopwords\n",
    "stopwords_pt_custom = [\n",
    "    # Artigos/Preposi√ß√µes/Pronomes\n",
    "    \"de\", \"a\", \"o\", \"que\", \"e\", \"do\", \"da\", \"em\", \"um\", \"para\", \"com\", \"nao\", \"uma\", \"os\", \"no\", \n",
    "    \"se\", \"na\", \"por\", \"mais\", \"as\", \"dos\", \"como\", \"mas\", \"ao\", \"ele\", \"das\", \"seu\", \"sua\", \"ou\", \n",
    "    \"quando\", \"muito\", \"nos\", \"ja\", \"eu\", \"tambem\", \"so\", \"pelo\", \"pela\", \"ate\", \"isso\", \"ela\", \n",
    "    \"entre\", \"depois\", \"sem\", \"mesmo\", \"aos\", \"seus\", \"quem\", \"nas\", \"me\", \"esse\", \"eles\", \"voc√™\", \n",
    "    \"foi\", \"desta\", \"deste\", \"pelas\", \"pelos\", \"nesta\", \"neste\", \n",
    "    \n",
    "    # NOVOS VIL√ïES (Detectados no Raio-X do Cluster 5)\n",
    "    \"devido\", \"ser\", \"realizacao\", \"fixacao\", \"reposicao\", \"dois\", \"reparos\", \"equipamentos\", \n",
    "    \"prr\", \"covid\", \"bateria\", # Bateria √© gen√©rico (carro? pilha?), melhor remover se for vago\n",
    "    \n",
    "    # Termos Gen√©ricos / Burocracia\n",
    "    \"aquisicao\", \"referente\", \"pagamento\", \"despesa\", \"servico\", \"servicos\", \"material\", \n",
    "    \"fornecimento\", \"nf\", \"nfs\", \"nota\", \"fiscal\", \"cupom\", \"valor\", \"pgto\", \"compra\", \n",
    "    \"consumo\", \"suprimento\", \"fundo\", \"recurso\", \"objeto\", \"item\", \"itens\", \"unidade\", \"unid\", \n",
    "    \"cx\", \"pct\", \"pc\", \"kg\", \"litro\", \"litros\", \"qtd\", \"quantidade\", \"nao\", \"informado\",\n",
    "    \"prestacao\", \"manutencao\", \"uso\", \"aplicacao\", \"total\", \"unitario\", \"valor\",\n",
    "    \"atender\", \"solicitacao\", \"pregao\", \"ata\", \"registro\", \"preco\", \"conforme\", \"atendimento\",\n",
    "    \"razao\", \"urgente\", \"disponivel\", \"utilizado\", \"pequeno\", \"grande\", \"novo\", \"velho\", \"aparelho\", \n",
    "    \"oficial\", \"produtos\", \n",
    "    \n",
    "    # Justificativas\n",
    "    \"acabar\", \"prestes\", \"falta\", \"rotina\", \"emergencia\", \"urgencia\",\n",
    "    \n",
    "    # Institui√ß√µes, Locais e CARGOS\n",
    "    \"pr\", \"rs\", \"prm\", \"dr\", \"dra\", \"sr\", \"sra\", \"ltda\", \"me\", \"epp\", \"sa\", \"co\", \"s/a\",\n",
    "    \"prmcruz\", \"altars\", \"sede\", \"prrs\", \"cnpj\", \"cpf\", \"procuradoria\", \"empresa\", \"orgao\",\n",
    "    \"procurador\", \"republica\", \"servidores\", \"servidor\",\n",
    "    \"blumenau\", \n",
    "    \n",
    "    # A√ß√µes e Adjetivos\n",
    "    \"instalacao\", \"substituicao\", \"conserto\", \"reparo\", \"troca\", \"confeccao\", \"locacao\",\n",
    "    \"gabinete\", \"sala\", \"almoxarifado\", \"estoque\", \"deposito\", \"setor\", \"unidades\", \"andar\",\n",
    "    \"materiais\", \"diversos\", \"pedagio\", \"utilizacao\", \"emergencial\", \"seguranca\", \"sistema\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    tokenizer = Tokenizer(inputCol=\"objeto_limpo\", outputCol=\"words_raw\")\n",
    "    df_tokenized = tokenizer.transform(df_clean_chars)\n",
    "\n",
    "    remover = StopWordsRemover(inputCol=\"words_raw\", outputCol=\"words_temp\")\n",
    "    remover.setStopWords(stopwords_pt_custom)\n",
    "    df_clean_temp = remover.transform(df_tokenized)\n",
    "\n",
    "# FILTRO SQL (Atualizado com 'servid' e 'defeit')\n",
    "    filter_expression = \"\"\"\n",
    "        filter(words_temp, x -> \n",
    "            x != '' AND \n",
    "            length(x) > 2 AND \n",
    "            NOT (length(x) == 4 AND substring(x, 1, 2) == 'pr') AND\n",
    "            substring(x, 1, 6) != 'necess' AND\n",
    "            substring(x, 1, 6) != 'demand' AND\n",
    "            substring(x, 1, 7) != 'apresen' AND\n",
    "            substring(x, 1, 7) != 'contrat' AND\n",
    "            substring(x, 1, 5) != 'possu' AND\n",
    "            substring(x, 1, 6) != 'servid' AND\n",
    "            substring(x, 1, 6) != 'defeit'\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    df_clean_nlp = df_clean_temp.withColumn(\"words_filtered\", expr(filter_expression))\n",
    "\n",
    "    df_final_nlp = df_clean_nlp.filter(size(col(\"words_filtered\")) > 0)\n",
    "\n",
    "    print(\"‚úÖ NLP V13 conclu√≠do.\")\n",
    "    df_final_nlp.select(\"objeto_aquisicao\", \"words_filtered\").show(5, truncate=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro NLP: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27958444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vetoriza√ß√£o V8 (Word2Vec Tunado para Pequenas Bases) ---\n",
      "Treinando modelo (isso pode levar alguns segundos a mais)...\n",
      "‚úÖ Vetoriza√ß√£o Word2Vec conclu√≠da.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 7 (V8 - Tuned): Vetoriza√ß√£o Sem√¢ntica (Word2Vec Ajustado)\n",
    "# ==============================================================================\n",
    "from pyspark.ml.feature import Word2Vec, Normalizer\n",
    "\n",
    "print(\"\\n--- Vetoriza√ß√£o V8 (Word2Vec Tunado para Pequenas Bases) ---\")\n",
    "\n",
    "try:\n",
    "    # AJUSTES DE HIPERPAR√ÇMETROS:\n",
    "    # vectorSize=50: Reduzi de 100 para 50 para evitar overfitting (vetores mais densos).\n",
    "    # maxIter=20: Aumentei para 20 passadas sobre os dados (aprende mais).\n",
    "    # windowSize=2: Janela curta para focar no produto vizinho e ignorar o departamento longe.\n",
    "    # minCount=2: Baixei para 2 para capturar mais vocabul√°rio t√©cnico.\n",
    "    \n",
    "    word2Vec = Word2Vec(vectorSize=50, \n",
    "                        minCount=2, \n",
    "                        inputCol=\"words_filtered\", \n",
    "                        outputCol=\"raw_features\",\n",
    "                        windowSize=2,\n",
    "                        maxIter=20,\n",
    "                        stepSize=0.025,\n",
    "                        seed=42)\n",
    "    \n",
    "    # Treinamento\n",
    "    print(\"Treinando modelo (isso pode levar alguns segundos a mais)...\")\n",
    "    model_w2v = word2Vec.fit(df_final_nlp)\n",
    "    df_w2v = model_w2v.transform(df_final_nlp)\n",
    "    \n",
    "    # Normaliza√ß√£o\n",
    "    normalizer = Normalizer(inputCol=\"raw_features\", outputCol=\"features\", p=2.0)\n",
    "    df_tfidf = normalizer.transform(df_w2v)\n",
    "    \n",
    "    df_tfidf.cache()\n",
    "    print(f\"‚úÖ Vetoriza√ß√£o Word2Vec conclu√≠da.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro Word2Vec: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50b90abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Auditando a Intelig√™ncia do Modelo Word2Vec ---\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'chave':\n",
      "+---------+------------------+\n",
      "|word     |similarity        |\n",
      "+---------+------------------+\n",
      "|chaves   |0.5950004458427429|\n",
      "|gaveteiro|0.5750795602798462|\n",
      "|copia    |0.5549104809761047|\n",
      "|tetra    |0.5181301832199097|\n",
      "|antessala|0.5160131454467773|\n",
      "+---------+------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'torneira':\n",
      "+---------+------------------+\n",
      "|word     |similarity        |\n",
      "+---------+------------------+\n",
      "|bebedouro|0.6883059740066528|\n",
      "|feminino |0.6138609647750854|\n",
      "|vazamento|0.602616012096405 |\n",
      "|cuba     |0.578112781047821 |\n",
      "|silica   |0.569718062877655 |\n",
      "+---------+------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'extintor':\n",
      "+----------+-------------------+\n",
      "|word      |similarity         |\n",
      "+----------+-------------------+\n",
      "|brigada   |0.5323852300643921 |\n",
      "|aviso     |0.5135721564292908 |\n",
      "|extintores|0.47751957178115845|\n",
      "|cartazes  |0.46337205171585083|\n",
      "|eletro    |0.4495670199394226 |\n",
      "+----------+-------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'gasolina':\n",
      "+-----------+------------------+\n",
      "|word       |similarity        |\n",
      "+-----------+------------------+\n",
      "|tempos     |0.5760372281074524|\n",
      "|combustivel|0.5555325746536255|\n",
      "|pneu       |0.5182271599769592|\n",
      "|oleo       |0.5001581311225891|\n",
      "|podium     |0.4617643654346466|\n",
      "+-----------+------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'limpeza':\n",
      "+------------+------------------+\n",
      "|word        |similarity        |\n",
      "+------------+------------------+\n",
      "|conservacao |0.6028355956077576|\n",
      "|graupp      |0.591882050037384 |\n",
      "|hipoclorito |0.5888473987579346|\n",
      "|entrega     |0.5720833539962769|\n",
      "|higienizacao|0.5220093131065369|\n",
      "+------------+------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'caneta':\n",
      "+------------+------------------+\n",
      "|word        |similarity        |\n",
      "+------------+------------------+\n",
      "|cartoes     |0.5660926103591919|\n",
      "|fotografias |0.5487976670265198|\n",
      "|galvanizada |0.5417946577072144|\n",
      "|baixo       |0.5382785201072693|\n",
      "|generalizado|0.5343340635299683|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# DIAGN√ìSTICO W2V: Teste de Similaridade Sem√¢ntica\n",
    "# ==============================================================================\n",
    "print(\"--- Auditando a Intelig√™ncia do Modelo Word2Vec ---\")\n",
    "\n",
    "# Escolha palavras que voc√™ sabe que existem na sua base e representam grupos distintos\n",
    "palavras_teste = [\"chave\", \"torneira\", \"extintor\", \"gasolina\", \"limpeza\", \"caneta\"]\n",
    "\n",
    "try:\n",
    "    for palavra in palavras_teste:\n",
    "        print(f\"\\nüîé Palavras mais pr√≥ximas de '{palavra}':\")\n",
    "        \n",
    "        # O m√©todo findSynonyms busca os vizinhos mais pr√≥ximos no espa√ßo vetorial\n",
    "        # O segundo argumento (5) √© quantas palavras queremos ver\n",
    "        try:\n",
    "            sinonimos = model_w2v.findSynonyms(palavra, 5)\n",
    "            sinonimos.show(truncate=False)\n",
    "        except Exception:\n",
    "            print(f\"   ‚ö†Ô∏è A palavra '{palavra}' n√£o foi encontrada no vocabul√°rio (talvez cortada pelo minCount).\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"‚ùå Erro: A vari√°vel 'model_w2v' n√£o existe. Rode a C√©lula 7 primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9b4b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Aplicando Bisecting K-Means (k=20) ---\n",
      "‚ùå Erro: [MISSING_GROUP_BY] The query does not include a GROUP BY clause. Add GROUP BY or turn it into the window functions using OVER clauses.;\n",
      "Aggregate [ano#0, unidade_gestora#1, nome_suprido#2, cpf_suprido#3, periodo_aplicacao#4, aprovado#5, data_aquisicao#6, nome_favorecido#7, cpf_cnpj_favorecido#8, objeto_aquisicao#9, valor_transacao#10, ano_partition#11, objeto_limpo#4194, words_raw#4211, words_temp#4232, words_filtered#4251, raw_features#4765, features#4789, aggregate_metrics(NormL2, ComputeM2, features#4789, 1.0, 0, 0) AS metrics#5999]\n",
      "+- Project [ano#0, unidade_gestora#1, nome_suprido#2, cpf_suprido#3, periodo_aplicacao#4, aprovado#5, data_aquisicao#6, nome_favorecido#7, cpf_cnpj_favorecido#8, objeto_aquisicao#9, valor_transacao#10, ano_partition#11, objeto_limpo#4194, words_raw#4211, words_temp#4232, words_filtered#4251, raw_features#4765, UDF(raw_features#4765) AS features#4789]\n",
      "   +- Project [ano#0, unidade_gestora#1, nome_suprido#2, cpf_suprido#3, periodo_aplicacao#4, aprovado#5, data_aquisicao#6, nome_favorecido#7, cpf_cnpj_favorecido#8, objeto_aquisicao#9, valor_transacao#10, ano_partition#11, objeto_limpo#4194, words_raw#4211, words_temp#4232, words_filtered#4251, UDF(words_filtered#4251) AS raw_features#4765]\n",
      "      +- Filter (size(words_filtered#4251, true) > 0)\n",
      "         +- Project [ano#0, unidade_gestora#1, nome_suprido#2, cpf_suprido#3, periodo_aplicacao#4, aprovado#5, data_aquisicao#6, nome_favorecido#7, cpf_cnpj_favorecido#8, objeto_aquisicao#9, valor_transacao#10, ano_partition#11, objeto_limpo#4194, words_raw#4211, words_temp#4232, filter(words_temp#4232, lambdafunction(((((NOT (lambda x#4252 = ) AND (length(lambda x#4252) > 2)) AND NOT ((length(lambda x#4252) = 4) AND (substring(lambda x#4252, 1, 2) = pr))) AND (NOT (substring(lambda x#4252, 1, 6) = necess) AND NOT (substring(lambda x#4252, 1, 6) = demand))) AND (((NOT (substring(lambda x#4252, 1, 7) = apresen) AND NOT (substring(lambda x#4252, 1, 7) = contrat)) AND NOT (substring(lambda x#4252, 1, 5) = possu)) AND (NOT (substring(lambda x#4252, 1, 6) = servid) AND NOT (substring(lambda x#4252, 1, 6) = defeit)))), lambda x#4252, false)) AS words_filtered#4251]\n",
      "            +- Project [ano#0, unidade_gestora#1, nome_suprido#2, cpf_suprido#3, periodo_aplicacao#4, aprovado#5, data_aquisicao#6, nome_favorecido#7, cpf_cnpj_favorecido#8, objeto_aquisicao#9, valor_transacao#10, ano_partition#11, objeto_limpo#4194, words_raw#4211, UDF(words_raw#4211) AS words_temp#4232]\n",
      "               +- Project [ano#0, unidade_gestora#1, nome_suprido#2, cpf_suprido#3, periodo_aplicacao#4, aprovado#5, data_aquisicao#6, nome_favorecido#7, cpf_cnpj_favorecido#8, objeto_aquisicao#9, valor_transacao#10, ano_partition#11, objeto_limpo#4194, UDF(objeto_limpo#4194) AS words_raw#4211]\n",
      "                  +- Project [ano#0, unidade_gestora#1, nome_suprido#2, cpf_suprido#3, periodo_aplicacao#4, aprovado#5, data_aquisicao#6, nome_favorecido#7, cpf_cnpj_favorecido#8, objeto_aquisicao#9, valor_transacao#10, ano_partition#11, regexp_replace(lower(objeto_aquisicao#9), [^a-z],  , 1) AS objeto_limpo#4194]\n",
      "                     +- Deduplicate [objeto_aquisicao#9, valor_transacao#10, nome_favorecido#7]\n",
      "                        +- Relation [ano#0,unidade_gestora#1,nome_suprido#2,cpf_suprido#3,periodo_aplicacao#4,aprovado#5,data_aquisicao#6,nome_favorecido#7,cpf_cnpj_favorecido#8,objeto_aquisicao#9,valor_transacao#10,ano_partition#11] parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 9 (V2.3): Bisecting K-Means - Corre√ß√£o de Vetores Vazios\n",
    "# ==============================================================================\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "K_FINAL = 20 \n",
    "\n",
    "print(f\"\\n--- Aplicando Bisecting K-Means (k={K_FINAL}) ---\")\n",
    "\n",
    "try:\n",
    "    # --- PASSO CR√çTICO: Filtrar vetores com norma zero ---\n",
    "    # Usamos o Summarizer para calcular a m√©trica de cada vetor\n",
    "    # Vetores que n√£o t√™m palavras resultam em norma 0.0\n",
    "    df_metrics = df_tfidf.withColumn(\"metrics\", Summarizer.metrics(\"normL2\").summary(col(\"features\")))\n",
    "    \n",
    "    # Filtramos apenas onde a norma L2 √© maior que zero\n",
    "    df_input = df_metrics.filter(col(\"metrics.normL2\")[0] > 0).drop(\"metrics\")\n",
    "\n",
    "    print(f\"üìä Registros com conte√∫do sem√¢ntico: {df_input.count()}\")\n",
    "\n",
    "    # Configura√ß√£o do Algoritmo\n",
    "    # Cosine distance exige vetores com magnitude > 0\n",
    "    bkmeans = BisectingKMeans(featuresCol=\"features\", \n",
    "                              k=K_FINAL, \n",
    "                              seed=1, \n",
    "                              predictionCol=\"prediction\", \n",
    "                              minDivisibleClusterSize=100,\n",
    "                              distanceMeasure=\"cosine\") \n",
    "    \n",
    "    model_final = bkmeans.fit(df_input)\n",
    "    df_clustered = model_final.transform(df_input)\n",
    "    \n",
    "    print(f\"‚úÖ Clusteriza√ß√£o conclu√≠da com sucesso.\")\n",
    "    \n",
    "    print(\"\\n--- Distribui√ß√£o dos Clusters ---\")\n",
    "    df_clustered.groupBy(\"prediction\").count().orderBy(\"prediction\").show(25)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
