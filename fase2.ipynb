{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94c21c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Fase 2: An√°lise Explorat√≥ria ---\n",
      "üìÇ Buscando base consolidada em: c:\\VSCode\\projetoMineracao\\dados\\Consolidado_Final\n",
      "‚úÖ Base carregada: 54196 registros.\n",
      "\n",
      "--- Saneamento da Base ---\n",
      "Total Bruto: 54196\n",
      "‚úÖ Total Real (√önicos): 12572\n",
      "üóëÔ∏è Lixo Removido: 41624\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# FASE 2: An√°lise Explorat√≥ria de Dados (EDA) e Minera√ß√£o (Completo)\n",
    "# Arquivo: analise_fase2.py\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Importa√ß√µes Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, size, lower, avg, stddev, abs as _abs, round as _round, max as _max, min as _min, count\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# --- 1. Configura√ß√£o de Ambiente (Windows) ---\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "print(\"--- Iniciando Fase 2: An√°lise Explorat√≥ria ---\")\n",
    "\n",
    "# --- 2. Inicializando Sess√£o Spark ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analise_Gastos_Fase2\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Otimiza√ß√£o Arrow\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# --- 3. Carregamento dos Dados ---\n",
    "BASE_DIR = os.path.join(os.getcwd(), \"dados\")\n",
    "input_path = os.path.join(BASE_DIR, \"Consolidado_Final\")\n",
    "\n",
    "print(f\"üìÇ Buscando base consolidada em: {input_path}\")\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"‚ùå ARQUIVO N√ÉO ENCONTRADO: {input_path}\")\n",
    "    sys.exit() # Encerra se n√£o achar o arquivo\n",
    "\n",
    "try:\n",
    "    df = spark.read.parquet(input_path)\n",
    "    df.cache() # Cache do dataset bruto\n",
    "    print(f\"‚úÖ Base carregada: {df.count()} registros.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro leitura: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CORRE√á√ÉO CR√çTICA: Remo√ß√£o de Duplicatas\n",
    "# ==============================================================================\n",
    "print(f\"\\n--- Saneamento da Base ---\")\n",
    "print(f\"Total Bruto: {df.count()}\")\n",
    "\n",
    "# Remove linhas onde Objeto, Valor e Favorecido s√£o id√™nticos\n",
    "# Isso elimina as repeti√ß√µes causadas pela fus√£o de c√©lulas no Excel\n",
    "df = df.dropDuplicates(['objeto_aquisicao', 'valor_transacao', 'nome_favorecido'])\n",
    "\n",
    "# For√ßa o rec√°lculo e cache na mem√≥ria\n",
    "df.cache()\n",
    "count_real = df.count()\n",
    "\n",
    "print(f\"‚úÖ Total Real (√önicos): {count_real}\")\n",
    "print(f\"üóëÔ∏è Lixo Removido: {54196 - count_real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61f0b390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando NLP V16 (Foco: Remover Justificativas) ---\n",
      "‚úÖ NLP V16 conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 6 (V16 - LIMPEZA DE JUSTIFICATIVAS): NLP Refinado\n",
    "# ==============================================================================\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, size, regexp_replace, expr, lower\n",
    "\n",
    "print(\"--- Iniciando NLP V16 (Foco: Remover Justificativas) ---\")\n",
    "\n",
    "# 1. Limpeza de Caracteres\n",
    "df_clean_chars = df.withColumn(\"objeto_limpo\", regexp_replace(lower(col(\"objeto_aquisicao\")), r\"[^a-z]\", \" \"))\n",
    "\n",
    "# 2. Stopwords Expandida (Baseada na sua √∫ltima auditoria)\n",
    "stopwords_pt_custom = [\n",
    "    # Artigos/Preposi√ß√µes B√°sicas\n",
    "    \"de\", \"a\", \"o\", \"que\", \"e\", \"do\", \"da\", \"em\", \"um\", \"para\", \"com\", \"nao\", \"uma\", \"os\", \"no\", \n",
    "    \"se\", \"na\", \"por\", \"mais\", \"as\", \"dos\", \"como\", \"mas\", \"ao\", \"ele\", \"das\", \"seu\", \"sua\", \"ou\", \n",
    "    \"quando\", \"muito\", \"nos\", \"ja\", \"eu\", \"tambem\", \"so\", \"pelo\", \"pela\", \"ate\", \"isso\", \"ela\", \n",
    "    \"entre\", \"depois\", \"sem\", \"mesmo\", \"aos\", \"seus\", \"quem\", \"nas\", \"me\", \"esse\", \"eles\", \"voce\", \n",
    "    \"foi\", \"desta\", \"deste\", \"pelas\", \"pelos\", \"nesta\", \"neste\", \"pois\", \"havia\",\n",
    "    \n",
    "    # JUSTIFICATIVAS (Os vil√µes dos Clusters 15, 17)\n",
    "    \"falta\", \"prestes\", \"acabar\", \"estoque\", \"razao\", \"motivo\", \"devido\", \"vista\", \"haja\",\n",
    "    \"considerando\", \"referente\", \"referida\", \"relativo\", \"conforme\", \"solicitado\", \"atender\", \n",
    "    \"atendimento\", \"necessidade\", \"necessario\", \"necessarios\", \"visando\", \"objeto\", \"visto\",\n",
    "    \"funcionamento\", \"bom\", \"mau\", \"impossibilidade\", \"urgencia\", \"emergencia\", \"carater\",\n",
    "    \n",
    "    # Processos Burocr√°ticos\n",
    "    \"pagamento\", \"aquisicao\", \"compra\", \"fornecimento\", \"servico\", \"servicos\", \"prestacao\",\n",
    "    \"entrega\", \"entregar\", \"empresa\", \"terceirizada\", \"contratada\", \"vulto\", \"monta\", \"despesa\",\n",
    "    \n",
    "    # Termos Gen√©ricos\n",
    "    \"unidade\", \"unid\", \"qtd\", \"quantidade\", \"material\", \"materiais\", \"consumo\", \"permanente\",\n",
    "    \"item\", \"itens\", \"produto\", \"produtos\", \"uso\", \"utilizacao\", \"aplicacao\", \"estoque\",\n",
    "    \"novo\", \"velho\", \"usado\", \"manutencao\", \"reparo\", \"conserto\", \"troca\", \"substituicao\",\n",
    "    \"especie\", \"tipo\", \"modelo\", \"marca\", \"cor\", \"tamanho\", \"oficial\", \"diversos\",\n",
    "    \n",
    "    # Institucional\n",
    "    \"pr\", \"prm\", \"dr\", \"dra\", \"sr\", \"sra\", \"secretaria\", \"departamento\", \"divisao\", \"setor\",\n",
    "    \"gabinete\", \"coordenadoria\", \"administracao\", \"regional\", \"publico\", \"federal\", \"estadual\",\n",
    "    \"municipio\", \"municipal\", \"processo\", \"protocolo\", \"memorando\", \"oficio\", \"despacho\",\n",
    "    \"lei\", \"decreto\", \"artigo\", \"portaria\", \"resolucao\", \"ata\", \"pregao\", \"licitacao\", \"prr\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    tokenizer = Tokenizer(inputCol=\"objeto_limpo\", outputCol=\"words_raw\")\n",
    "    df_tokenized = tokenizer.transform(df_clean_chars)\n",
    "\n",
    "    remover = StopWordsRemover(inputCol=\"words_raw\", outputCol=\"words_temp\")\n",
    "    remover.setStopWords(stopwords_pt_custom)\n",
    "    df_clean_temp = remover.transform(df_tokenized)\n",
    "\n",
    "    # FILTRO SQL (Mantido e refor√ßado)\n",
    "    filter_expression = \"\"\"\n",
    "        filter(words_temp, x -> \n",
    "            x != '' AND \n",
    "            length(x) > 2 AND \n",
    "            NOT (length(x) == 4 AND substring(x, 1, 2) == 'pr') AND\n",
    "            substring(x, 1, 6) != 'necess' AND\n",
    "            substring(x, 1, 6) != 'demand' AND\n",
    "            substring(x, 1, 7) != 'solicit' AND\n",
    "            substring(x, 1, 7) != 'apresen' AND\n",
    "            substring(x, 1, 7) != 'contrat' AND\n",
    "            substring(x, 1, 7) != 'pagamen' AND\n",
    "            substring(x, 1, 7) != 'forneci' AND\n",
    "            substring(x, 1, 5) != 'possu' AND\n",
    "            substring(x, 1, 6) != 'servid' AND\n",
    "            substring(x, 1, 6) != 'defeit' AND\n",
    "            substring(x, 1, 7) != 'disponi' AND\n",
    "            substring(x, 1, 6) != 'inexis' AND\n",
    "            substring(x, 1, 6) != 'inform' AND\n",
    "            substring(x, 1, 5) != 'urgen' AND\n",
    "            substring(x, 1, 5) != 'emerg' AND\n",
    "            substring(x, 1, 7) != 'justifi' AND\n",
    "            substring(x, 1, 5) != 'almox' AND\n",
    "            substring(x, 1, 5) != 'reemb'\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    df_clean_nlp = df_clean_temp.withColumn(\"words_filtered\", expr(filter_expression))\n",
    "    df_final_nlp = df_clean_nlp.filter(size(col(\"words_filtered\")) > 0)\n",
    "\n",
    "    print(\"‚úÖ NLP V16 conclu√≠do.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro NLP: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27958444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vetoriza√ß√£o V10 (minCount=5 para robustez) ---\n",
      "‚úÖ Vetoriza√ß√£o conclu√≠da.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 7 (V10): Vetoriza√ß√£o Word2Vec (minCount=5)\n",
    "# ==============================================================================\n",
    "from pyspark.ml.feature import Word2Vec, Normalizer\n",
    "\n",
    "print(\"\\n--- Vetoriza√ß√£o V10 (minCount=5 para robustez) ---\")\n",
    "\n",
    "try:\n",
    "    word2Vec = Word2Vec(vectorSize=50, \n",
    "                        minCount=5,   # <--- AUMENTAMOS PARA LIMPAR RU√çDO\n",
    "                        inputCol=\"words_filtered\", \n",
    "                        outputCol=\"raw_features\",\n",
    "                        windowSize=2,\n",
    "                        maxIter=20,\n",
    "                        stepSize=0.025,\n",
    "                        seed=42)\n",
    "    \n",
    "    model_w2v = word2Vec.fit(df_final_nlp)\n",
    "    df_w2v = model_w2v.transform(df_final_nlp)\n",
    "    \n",
    "    normalizer = Normalizer(inputCol=\"raw_features\", outputCol=\"features\", p=2.0)\n",
    "    df_tfidf = normalizer.transform(df_w2v) \n",
    "    \n",
    "    df_tfidf.cache()\n",
    "    print(f\"‚úÖ Vetoriza√ß√£o conclu√≠da.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro Word2Vec: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50b90abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Auditando a Intelig√™ncia do Modelo Word2Vec ---\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'chave':\n",
      "+---------+------------------+\n",
      "|word     |similarity        |\n",
      "+---------+------------------+\n",
      "|copia    |0.6501355171203613|\n",
      "|chaves   |0.6043857932090759|\n",
      "|miolo    |0.5669997930526733|\n",
      "|gaveteiro|0.5602972507476807|\n",
      "|yale     |0.5508624911308289|\n",
      "+---------+------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'torneira':\n",
      "+---------+------------------+\n",
      "|word     |similarity        |\n",
      "+---------+------------------+\n",
      "|peca     |0.6849445104598999|\n",
      "|tanque   |0.6733036637306213|\n",
      "|cuba     |0.609876811504364 |\n",
      "|vazamento|0.5764372944831848|\n",
      "|mangueira|0.5273012518882751|\n",
      "+---------+------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'extintor':\n",
      "+----------+-------------------+\n",
      "|word      |similarity         |\n",
      "+----------+-------------------+\n",
      "|extintores|0.45838749408721924|\n",
      "|fixar     |0.4460994005203247 |\n",
      "|colar     |0.42804038524627686|\n",
      "|estancar  |0.40989598631858826|\n",
      "|parou     |0.40917545557022095|\n",
      "+----------+-------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'gasolina':\n",
      "+-----------+-------------------+\n",
      "|word       |similarity         |\n",
      "+-----------+-------------------+\n",
      "|litro      |0.5582453608512878 |\n",
      "|oleo       |0.523969829082489  |\n",
      "|transportar|0.5209729075431824 |\n",
      "|fluence    |0.46273574233055115|\n",
      "|palio      |0.4452992081642151 |\n",
      "+-----------+-------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'limpeza':\n",
      "+------------+------------------+\n",
      "|word        |similarity        |\n",
      "+------------+------------------+\n",
      "|higiene     |0.566277265548706 |\n",
      "|higienizacao|0.55428147315979  |\n",
      "|maos        |0.5047265291213989|\n",
      "|iguacu      |0.5028831958770752|\n",
      "|insumos     |0.4937968850135803|\n",
      "+------------+------------------+\n",
      "\n",
      "\n",
      "üîé Palavras mais pr√≥ximas de 'caneta':\n",
      "+--------+-------------------+\n",
      "|word    |similarity         |\n",
      "+--------+-------------------+\n",
      "|cartoes |0.5796734690666199 |\n",
      "|pedro   |0.501510500907898  |\n",
      "|colorida|0.48771730065345764|\n",
      "|formato |0.484538197517395  |\n",
      "|similar |0.4803576171398163 |\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# DIAGN√ìSTICO W2V: Teste de Similaridade Sem√¢ntica\n",
    "# ==============================================================================\n",
    "print(\"--- Auditando a Intelig√™ncia do Modelo Word2Vec ---\")\n",
    "\n",
    "# Escolha palavras que voc√™ sabe que existem na sua base e representam grupos distintos\n",
    "palavras_teste = [\"chave\", \"torneira\", \"extintor\", \"gasolina\", \"limpeza\", \"caneta\"]\n",
    "\n",
    "try:\n",
    "    for palavra in palavras_teste:\n",
    "        print(f\"\\nüîé Palavras mais pr√≥ximas de '{palavra}':\")\n",
    "        \n",
    "        # O m√©todo findSynonyms busca os vizinhos mais pr√≥ximos no espa√ßo vetorial\n",
    "        # O segundo argumento (5) √© quantas palavras queremos ver\n",
    "        try:\n",
    "            sinonimos = model_w2v.findSynonyms(palavra, 5)\n",
    "            sinonimos.show(truncate=False)\n",
    "        except Exception:\n",
    "            print(f\"   ‚ö†Ô∏è A palavra '{palavra}' n√£o foi encontrada no vocabul√°rio (talvez cortada pelo minCount).\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"‚ùå Erro: A vari√°vel 'model_w2v' n√£o existe. Rode a C√©lula 7 primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9b4b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Aplicando Bisecting K-Means (k=20) ---\n",
      "üìä Registros v√°lidos para clusteriza√ß√£o: 11974\n",
      "‚úÖ Clusteriza√ß√£o k=20 conclu√≠da.\n",
      "\n",
      "--- Distribui√ß√£o dos Clusters ---\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|  361|\n",
      "|         1|  765|\n",
      "|         2|  607|\n",
      "|         3|  657|\n",
      "|         4|  536|\n",
      "|         5|  575|\n",
      "|         6|  800|\n",
      "|         7|  537|\n",
      "|         8|  315|\n",
      "|         9|  593|\n",
      "|        10|  691|\n",
      "|        11|  256|\n",
      "|        12|  728|\n",
      "|        13|  609|\n",
      "|        14|  367|\n",
      "|        15|  520|\n",
      "|        16| 1044|\n",
      "|        17| 1146|\n",
      "|        18|  379|\n",
      "|        19|  488|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 9 (V4.1): Bisecting K-Means (K=10) - CORRIGIDA\n",
    "# ==============================================================================\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# K REDUZIDO PARA 10 GRUPOS\n",
    "K_FINAL = 20\n",
    "\n",
    "print(f\"\\n--- Aplicando Bisecting K-Means (k={K_FINAL}) ---\")\n",
    "\n",
    "try:\n",
    "    # 1. CRIAMOS UMA UDF PARA CALCULAR A NORMA DO VETOR\n",
    "    # Isso evita o erro de agrega√ß√£o do Summarizer e funciona linha a linha.\n",
    "    @udf(returnType=DoubleType())\n",
    "    def get_vector_norm(v):\n",
    "        try:\n",
    "            # Retorna a norma L2 (magnitude) do vetor denso ou esparso\n",
    "            return float(v.norm(2))\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    # 2. FILTRAGEM SEGURA\n",
    "    # Calculamos a norma e filtramos apenas quem tem tamanho > 0\n",
    "    df_metrics = df_tfidf.withColumn(\"vector_norm\", get_vector_norm(col(\"features\")))\n",
    "    df_input = df_metrics.filter(col(\"vector_norm\") > 0).drop(\"vector_norm\")\n",
    "\n",
    "    total_validos = df_input.count()\n",
    "    print(f\"üìä Registros v√°lidos para clusteriza√ß√£o: {total_validos}\")\n",
    "\n",
    "    # 3. CLUSTERIZA√á√ÉO\n",
    "    bkmeans = BisectingKMeans(featuresCol=\"features\", \n",
    "                              k=K_FINAL, \n",
    "                              seed=1, \n",
    "                              predictionCol=\"prediction\", \n",
    "                              minDivisibleClusterSize=100, \n",
    "                              distanceMeasure=\"cosine\")\n",
    "    \n",
    "    model_final = bkmeans.fit(df_input)\n",
    "    df_clustered = model_final.transform(df_input)\n",
    "    \n",
    "    print(f\"‚úÖ Clusteriza√ß√£o k={K_FINAL} conclu√≠da.\")\n",
    "    \n",
    "    print(\"\\n--- Distribui√ß√£o dos Clusters ---\")\n",
    "    df_clustered.groupBy(\"prediction\").count().orderBy(\"prediction\").show(25)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "229d9d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Auditoria Detalhada dos Clusters (Keywords + Exemplos) ---\n",
      "\n",
      "1. Calculando as palavras mais frequentes de cada grupo...\n",
      "2. Selecionando amostras aleat√≥rias...\n",
      "\n",
      "====================================================================================================\n",
      "                                       RELAT√ìRIO DE CLUSTERS                                        \n",
      "====================================================================================================\n",
      "\n",
      "üìÇ CLUSTER 0\n",
      "üîë PALAVRAS-CHAVE: [VEICULO, PLACA, LAVAGEM, ABASTECIMENTO, OLEO, GASOLINA, PNEU]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$    100.00 | gasolina                                                              \n",
      " ‚Ä¢ R$     50.00 | servico de reconhecimento de firma a pedido do secretario estadual    \n",
      " ‚Ä¢ R$     61.60 | necessidade urgente de aquisicao da tampa de oleo do motor para o veic\n",
      " ‚Ä¢ R$     61.32 | passagem de balsa para veiculo oficial em diligencia ao municipio de b\n",
      " ‚Ä¢ R$     60.00 | lavagem do veiculo  l200  placa oaz8882                               \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 1\n",
      "üîë PALAVRAS-CHAVE: [PEDAGIO, REPUBLICA, VIAGEM, PROCURADOR, ITINERANCIA, SAO, ISENCAO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     26.80 | saque para pagamentos de pedagios em deslocamento de viatura para o pr\n",
      " ‚Ä¢ R$      5.50 | despesa com pagamento de pedagio                                      \n",
      " ‚Ä¢ R$      7.50 | pagamento de pedagio                                                  \n",
      " ‚Ä¢ R$     35.00 | aquisicao de carimbo de servidorportal de pedidos n 19652servidor sirl\n",
      " ‚Ä¢ R$      7.10 | pagamento de pedagio conduzindo membro em itinerancia                 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 2\n",
      "üîë PALAVRAS-CHAVE: [COVID, ALCOOL, GEL, PREVENCAO, PROTECAO, PANDEMIA, RETORNO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$    389.90 | para controle de acesso as pessoas atraves da afericao de temperatura \n",
      " ‚Ä¢ R$    150.00 | considerando que o retorno as atividades presenciais ocorreu no dia 13\n",
      " ‚Ä¢ R$    144.51 | 49389 litros de oleo diesel                                           \n",
      " ‚Ä¢ R$    109.89 | preparacao do predio para retorno das atividades presenciais com a ado\n",
      " ‚Ä¢ R$     42.00 | nf 000001507  ref aquisicao de 01 pulverizador 2 litros para atender n\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 3\n",
      "üîë PALAVRAS-CHAVE: [SEGURANCA, DOCUMENTOS, CONFECCAO, IMPRESSAO, PROCURADORIA, SECAO, TRANSPORTE]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     28.00 | aquisicao de material publicidade ascomprr4\n",
      "portal de pedidos n 18303 \n",
      " ‚Ä¢ R$     41.00 | aquisicao de materiais para uso em treinamento brigada de incendio    \n",
      " ‚Ä¢ R$     74.90 | impressao de banner para evento                                       \n",
      " ‚Ä¢ R$     28.15 | material eletriconaeletronico que nao tem na secao de material da prrj\n",
      " ‚Ä¢ R$     30.00 | composicao grafica para ilustrar o horario de atendimento ao publico d\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 4\n",
      "üîë PALAVRAS-CHAVE: [PEQUENO, VALOR, DESPESAS, PEQUENA, PILHA, ALCALINA, PILHAS]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     39.92 | 8 pacotes de acucar cristal no valor de 499 cada adquirido para uso na\n",
      " ‚Ä¢ R$    187.60 | aparelhos de telefonia fixa para que todos os colaboradores da prmnova\n",
      " ‚Ä¢ R$    150.00 | materiais nao existentes no almoxarifado da prpi e cuja aquisicao se f\n",
      " ‚Ä¢ R$     28.00 | compra de pequena monta                                               \n",
      " ‚Ä¢ R$    185.00 | 06 un pilha alcalina palito aaa  \n",
      "01 un pilha alcalina pequena aa     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 5\n",
      "üîë PALAVRAS-CHAVE: [MEDICO, ODONTOLOGICO, ENFERMAGEM, SUPRIMENTO, FUNDOS, PAPEL, CARIMBO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     31.80 | aquisicao para teste de impressora termica e escolha de modelo para co\n",
      " ‚Ä¢ R$     49.26 | aquisicao emergencial de etiqueta para impressora zebra por falta no a\n",
      " ‚Ä¢ R$    100.77 | solicitado pelo setor odontologico                                    \n",
      " ‚Ä¢ R$     15.95 | compra de termometro digital para uso do posto medico da prrj  01 unid\n",
      " ‚Ä¢ R$     65.00 | impressao de folhas                                                   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 6\n",
      "üîë PALAVRAS-CHAVE: [CAFE, LIMPEZA, COPA, AGUA, COPEIRAGEM, FILTRO, SUPRIR]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$    137.40 | fabricacao  de  paletes  que acondicionarao os fardos de acucar do alm\n",
      " ‚Ä¢ R$    350.00 | servico de limpeza de reservatorio de agua                            \n",
      " ‚Ä¢ R$    199.90 | instrumentacao da copa da prmnova friburgo                            \n",
      " ‚Ä¢ R$     70.00 | 1 caixa de mascaras descartaveis                                      \n",
      " ‚Ä¢ R$     22.80 | pano multiuso guardanapo e detergente liquido                         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 7\n",
      "üîë PALAVRAS-CHAVE: [GAS, AGUA, GLP, BOTIJAO, COZINHA, MINERAL, COPA]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     60.00 | botijao de gas glp 13kg                                               \n",
      " ‚Ä¢ R$    152.50 | material de consumo utilizado para manutencao predial da prmsousa     \n",
      " ‚Ä¢ R$    200.00 | servicos prestados de tratamento da piscina manutencao do filtro e for\n",
      " ‚Ä¢ R$    100.00 | mangueira cristal 12 g para uso em ar condicionado  50m x r 200       \n",
      " ‚Ä¢ R$    144.50 | aquisicao de recarga de gas para ar condicionado da sala de reunioes d\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 8\n",
      "üîë PALAVRAS-CHAVE: [TINTA, MASSA, REPAROS, CIMENTO, AREIA, PEQUENOS, ACRILICA]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$      7.83 | prego comum ccabeca 18x27  1kg para reparos emergenciais bandejas salv\n",
      " ‚Ä¢ R$      9.00 | uma caixa de cola durepoxi para uso na manutencao do predio           \n",
      " ‚Ä¢ R$     25.00 | servico de acabamento                                                 \n",
      " ‚Ä¢ R$    265.00 | aquisicao de caixa de arquivo morto                                   \n",
      " ‚Ä¢ R$     22.00 | bomil reboco interno 30 kg bomil aci argamassa 15 kg                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 9\n",
      "üîë PALAVRAS-CHAVE: [CAIXA, SANITARIO, VASO, TORNEIRA, VALVULA, VEDACAO, BANHEIRO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     30.30 | abracadeira de aco para reparos em tubulacao bomba de agua 2 x 1515   \n",
      " ‚Ä¢ R$     60.00 | botao acionador caixa acoplada deca                                   \n",
      " ‚Ä¢ R$     51.76 | torneira jardimttanq 2 e uniao torneira 34 2                          \n",
      " ‚Ä¢ R$      6.00 | 01 sifao flexivel                                                     \n",
      " ‚Ä¢ R$     26.26 | aquisicao de um canobengala de 40 mm em pvc para descarga e um tubo de\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 10\n",
      "üîë PALAVRAS-CHAVE: [PARAFUSOS, FIXACAO, PARAFUSO, ACO, COLA, ADESIVO, SUPORTE]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     12.98 | parafuso madaglommdf 50x50mm cht philbic chipboard                    \n",
      " ‚Ä¢ R$    250.00 | servico de rebobinemnto com servico de torno com adaptaca para rolamen\n",
      " ‚Ä¢ R$      5.00 | porcas 532 10un x r 0                                                 \n",
      " ‚Ä¢ R$     19.50 | plastico adesivo contact para atender a solicitacao da disot colar avi\n",
      " ‚Ä¢ R$     26.49 | protetor para quina redondo e massa plastica                          \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 11\n",
      "üîë PALAVRAS-CHAVE: [FITA, DUPLA, FACE, ADESIVA, ROSCA, ISOLANTE, VEDA]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     43.80 | tratase de aquisicao de silicone e fita adesiva                       \n",
      " ‚Ä¢ R$     68.82 | fita colada mao francesa mdf cortado e fita de borda                  \n",
      " ‚Ä¢ R$     21.60 | aplicador silicone                                                    \n",
      " ‚Ä¢ R$     18.70 | argamassa e graxa                                                     \n",
      " ‚Ä¢ R$     32.47 | aquisicao de fita isolante e extensao de cinco metro para uso no cpd  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 12\n",
      "üîë PALAVRAS-CHAVE: [UNIDADES, CABO, PVC, TOMADA, PLUG, METROS, PINO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$      1.00 | compra de cabo eletroboia  15 a                                       \n",
      " ‚Ä¢ R$      4.60 | porca 38s curta  1435100 2pc x r230                                   \n",
      " ‚Ä¢ R$     38.80 | compra de lampada eletrica 15w 127 v  04 unidades                     \n",
      " ‚Ä¢ R$      9.00 | cordao paralelo 250 mm2 br car  5 metros                              \n",
      " ‚Ä¢ R$     28.00 | compra de plug macho 10a a pedido setor do setor informatica no qual s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 13\n",
      "üîë PALAVRAS-CHAVE: [CHAVES, COPIAS, COPIA, CHAVE, CONFECCAO, SALA, DUAS]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$      7.00 | servico de copia de chave para gateiro de mesa a pedido da servidora a\n",
      " ‚Ä¢ R$     21.00 | impressoes de projetos                                                \n",
      " ‚Ä¢ R$     40.00 | confeccao de copias de chaves para a prmparanavai tendo em vista extin\n",
      " ‚Ä¢ R$     79.80 | aquisicao de caixas para fins de arquivar feitos e organizar o arquivo\n",
      " ‚Ä¢ R$     76.00 | suportes para extintores de incendio solicitados pel0s bombeiros      \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 14\n",
      "üîë PALAVRAS-CHAVE: [SALA, PLACA, PORTA, SINALIZACAO, INSTALACAO, PINTURA, PAREDE]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     52.30 | base para rele foto e rele foto eletrico                              \n",
      " ‚Ä¢ R$    270.00 | compra de fechaduras para gabinete de procurador sala do sjur e armari\n",
      " ‚Ä¢ R$     71.20 | construcao de piso para conteiner de lixo e reforma da escada de acess\n",
      " ‚Ä¢ R$    199.50 | aquisicao de fones de ouvido para assessoria do 4 oficio da prmblumena\n",
      " ‚Ä¢ R$    100.00 | confeccao de uma placa adesiva que sera colada sobre antiga placa de m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 15\n",
      "üîë PALAVRAS-CHAVE: [PORTA, FECHADURA, PORTAO, VIDRO, ACESSO, ENTRADA, PORTAS]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$    286.00 | aquisicao de porta da assessoria do gabinete para instalacao de fechad\n",
      " ‚Ä¢ R$     13.80 | trincos parta fechamento de portas da cgp e no 10 andar 2 x 690       \n",
      " ‚Ä¢ R$     25.00 | substituicao de baterias de controles remotos dos portoes externos da \n",
      " ‚Ä¢ R$    240.00 | servico de conserto no motor do portao do estacionamento do edificiose\n",
      " ‚Ä¢ R$     17.88 | reposicao parcial do estoque do almoxarifado cotacao eletronica em tra\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 16\n",
      "üîë PALAVRAS-CHAVE: [SEDE, BANHEIRO, PREDIO, ANDAR, AGUA, TORNEIRA, VAZAMENTO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     87.00 | para reparar o piso do g3                                             \n",
      " ‚Ä¢ R$    129.00 | aquisicao de uma valula de servico split para manutencao ar condiciona\n",
      " ‚Ä¢ R$    230.00 | conserto do refrigerador da copa  foi necessaria a troca do ventilador\n",
      " ‚Ä¢ R$      6.36 | material solicitado pelos terceirizados da prrj que estiveram na prmca\n",
      " ‚Ä¢ R$     72.36 | solicito seja adquirido o material  com o objetivo de auxiliar o servi\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 17\n",
      "üîë PALAVRAS-CHAVE: [INSTALACAO, SALA, CONDICIONADO, ELETRICA, APARELHO, SISTEMA, PORTAO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$    230.00 | aluguel de aparelho de som para utilizacao da inauguracao da prm      \n",
      " ‚Ä¢ R$    171.96 | materiais para instalacao de ar condicionado na cgp na dicgc e no 15 a\n",
      " ‚Ä¢ R$     75.00 | considerando a necessidade de realizar manutencao na central dos os te\n",
      " ‚Ä¢ R$      3.05 | para servico de colocacao de aparelho split na sala 605 da prrj       \n",
      " ‚Ä¢ R$     41.00 | material eletrico e suporte para tv visando realizar reparos e adequac\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 18\n",
      "üîë PALAVRAS-CHAVE: [PILHAS, PREDIAL, CONTROLES, CONTROLE, ALCALINAS, AAA, CONDICIONADO]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$     89.20 | aquisicao de oito 08 canaletas 20x10mm de dois metros cada cem 100 con\n",
      " ‚Ä¢ R$     18.00 | utilizacao nos controles remotos de equipamentos da prpi              \n",
      " ‚Ä¢ R$    136.00 | aquisicao de de 8 bateria de 9v e 12 pilhas aa para utilizacao nos mic\n",
      " ‚Ä¢ R$    124.91 | bateria para os bastoes de ronda pilhas para os controles de ar condic\n",
      " ‚Ä¢ R$     11.60 | material necessario para manutencao das paredes da prm que estao sendo\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìÇ CLUSTER 19\n",
      "üîë PALAVRAS-CHAVE: [LAMPADAS, LED, SELOG, LAMPADA, QUEIMADAS, REPOSICAO, REATOR]\n",
      "----------------------------------------------------------------------------------------------------\n",
      " ‚Ä¢ R$    241.26 | aquisicao de lampadas eletricas para substituicao das queimadas       \n",
      " ‚Ä¢ R$     16.74 | sistema de troca de lampadas fluorescentes para lampadas de led da prm\n",
      " ‚Ä¢ R$     51.50 | compra de lampada para ser usada no refletor da antiga sede           \n",
      " ‚Ä¢ R$    110.00 | nova aquisicao de reator para substituir outro reator queimado no refl\n",
      " ‚Ä¢ R$     38.60 | reator elet 2x40wbiv                                                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA DE AUDITORIA (V2): Top Palavras + Exemplos\n",
    "# ==============================================================================\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col, rand, explode, count, desc\n",
    "\n",
    "print(\"--- Auditoria Detalhada dos Clusters (Keywords + Exemplos) ---\\n\")\n",
    "\n",
    "# --- PARTE 1: Descobrir as Top 7 Palavras por Cluster ---\n",
    "print(\"1. Calculando as palavras mais frequentes de cada grupo...\")\n",
    "\n",
    "# 1. Explode: Transforma ['pneu', 'aro'] em duas linhas: 'pneu' e 'aro'\n",
    "df_exploded = df_clustered.withColumn(\"word\", explode(col(\"words_filtered\")))\n",
    "\n",
    "# 2. Conta frequ√™ncia: Quantas vezes a palavra aparece em cada cluster\n",
    "df_word_counts = df_exploded.groupBy(\"prediction\", \"word\").count()\n",
    "\n",
    "# 3. Rankeia: Pega as Top 7\n",
    "w_rank = Window.partitionBy(\"prediction\").orderBy(col(\"count\").desc())\n",
    "df_top_keywords = df_word_counts.withColumn(\"rank\", row_number().over(w_rank)) \\\n",
    "                                .filter(col(\"rank\") <= 7) \\\n",
    "                                .orderBy(\"prediction\", \"rank\")\n",
    "\n",
    "# 4. Traz para a mem√≥ria (Dicion√°rio Python) para exibi√ß√£o r√°pida\n",
    "# Estrutura final: {0: \"pneu, aro, camara...\", 1: \"caneta, lapis...\"}\n",
    "keywords_data = df_top_keywords.collect()\n",
    "keywords_dict = {}\n",
    "\n",
    "for row in keywords_data:\n",
    "    cluster_id = row['prediction']\n",
    "    word = row['word']\n",
    "    if cluster_id not in keywords_dict:\n",
    "        keywords_dict[cluster_id] = []\n",
    "    keywords_dict[cluster_id].append(word)\n",
    "\n",
    "# --- PARTE 2: Pegar 5 Exemplos Aleat√≥rios (C√≥digo anterior) ---\n",
    "print(\"2. Selecionando amostras aleat√≥rias...\")\n",
    "w_sample = Window.partitionBy(\"prediction\").orderBy(rand(seed=42))\n",
    "df_amostra = df_clustered.withColumn(\"rn\", row_number().over(w_sample)) \\\n",
    "                          .filter(col(\"rn\") <= 5) \\\n",
    "                          .select(\"prediction\", \"objeto_aquisicao\", \"valor_transacao\", \"words_filtered\")\n",
    "\n",
    "amostras = df_amostra.collect()\n",
    "amostras_ordenadas = sorted(amostras, key=lambda x: x['prediction'])\n",
    "\n",
    "# --- PARTE 3: Exibi√ß√£o do Relat√≥rio ---\n",
    "from itertools import groupby\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"{'RELAT√ìRIO DE CLUSTERS':^100}\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "for cluster_id, itens in groupby(amostras_ordenadas, key=lambda x: x['prediction']):\n",
    "    \n",
    "    # Monta a string de palavras-chave\n",
    "    top_words = keywords_dict.get(cluster_id, [\"(Sem palavras suficientes)\"])\n",
    "    top_words_str = \", \".join(top_words).upper()\n",
    "    \n",
    "    print(f\"üìÇ CLUSTER {cluster_id}\")\n",
    "    print(f\"üîë PALAVRAS-CHAVE: [{top_words_str}]\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for item in itens:\n",
    "        # Formata√ß√£o: Pre√ßo alinhado √† direita | Texto original truncado\n",
    "        print(f\" ‚Ä¢ R$ {item['valor_transacao']:>9.2f} | {item['objeto_aquisicao'][:70]:<70}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01611c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Calculando Estat√≠sticas Globais dos Clusters ---\n",
      "\n",
      "--- 2. Resumo de Contamina√ß√£o por Cluster ---\n",
      "+----------+-------------------+------------+-------------+\n",
      "|prediction|total_itens_cluster|qtd_outliers|perc_outliers|\n",
      "+----------+-------------------+------------+-------------+\n",
      "|         1|                765|         114|         14.9|\n",
      "|        12|                728|          83|         11.4|\n",
      "|         8|                315|          35|        11.11|\n",
      "|        10|                691|          74|        10.71|\n",
      "|         4|                536|          56|        10.45|\n",
      "|        15|                520|          50|         9.62|\n",
      "|         9|                593|          55|         9.27|\n",
      "|        13|                609|          56|          9.2|\n",
      "|         5|                575|          52|         9.04|\n",
      "|        14|                367|          32|         8.72|\n",
      "|        16|               1044|          87|         8.33|\n",
      "|         3|                657|          53|         8.07|\n",
      "|         7|                537|          40|         7.45|\n",
      "|        11|                256|          19|         7.42|\n",
      "|         2|                607|          44|         7.25|\n",
      "|        18|                379|          26|         6.86|\n",
      "|        17|               1146|          74|         6.46|\n",
      "|        19|                488|          29|         5.94|\n",
      "|         6|                800|          44|          5.5|\n",
      "|         0|                361|          17|         4.71|\n",
      "+----------+-------------------+------------+-------------+\n",
      "\n",
      "--- 3. Extraindo os Top 10 Casos Graves por Cluster ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\VSCode\\projetoMineracao\\venv\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:111: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 4.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Arquivo 'relatorio_top10_outliers.csv' gerado com sucesso!\n",
      "   Conte√∫do: Os 10 maiores desvios de cada um dos clusters.\n",
      "   Local: c:\\VSCode\\projetoMineracao/relatorio_top10_outliers.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 10 (Relat√≥rio Estruturado): Top 10 Outliers + Estat√≠sticas por Cluster\n",
    "# ==============================================================================\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import expr, col, round, count, desc, row_number, lit\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"--- 1. Calculando Estat√≠sticas Globais dos Clusters ---\")\n",
    "\n",
    "# 1. Totais por Cluster (Quantos itens existem no total?)\n",
    "df_totais = df_clustered.groupBy(\"prediction\").agg(count(\"*\").alias(\"total_itens_cluster\"))\n",
    "\n",
    "# 2. C√°lculo dos Limites IQR (Q1, Mediana, Q3, Teto)\n",
    "df_quartis = df_clustered.groupBy(\"prediction\").agg(\n",
    "    expr(\"percentile_approx(valor_transacao, 0.25)\").alias(\"Q1\"),\n",
    "    expr(\"percentile_approx(valor_transacao, 0.50)\").alias(\"Mediana\"),\n",
    "    expr(\"percentile_approx(valor_transacao, 0.75)\").alias(\"Q3\")\n",
    ")\n",
    "\n",
    "df_limites = df_quartis.withColumn(\"IQR\", col(\"Q3\") - col(\"Q1\")) \\\n",
    "                       .withColumn(\"limite_superior\", col(\"Q3\") + (1.5 * col(\"IQR\")))\n",
    "\n",
    "# 3. Cruzamento com dados originais\n",
    "df_analise = df_clustered.join(df_limites, on=\"prediction\", how=\"inner\") \\\n",
    "                          .join(df_totais, on=\"prediction\", how=\"inner\")\n",
    "\n",
    "# 4. Filtrando Outliers\n",
    "# Regra: Acima do teto E acima de R$ 50,00\n",
    "df_outliers_raw = df_analise.filter((col(\"valor_transacao\") > col(\"limite_superior\")) & \n",
    "                                    (col(\"valor_transacao\") > 50))\n",
    "\n",
    "# ==============================================================================\n",
    "# PARTE A: ESTAT√çSTICAS DE PORCENTAGEM (Visualiza√ß√£o no Console)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 2. Resumo de Contamina√ß√£o por Cluster ---\")\n",
    "\n",
    "# Conta quantos outliers tem em cada cluster\n",
    "df_stats_outliers = df_outliers_raw.groupBy(\"prediction\", \"total_itens_cluster\").agg(count(\"*\").alias(\"qtd_outliers\"))\n",
    "\n",
    "# Calcula a porcentagem\n",
    "df_resumo = df_stats_outliers.withColumn(\"perc_outliers\", round((col(\"qtd_outliers\") / col(\"total_itens_cluster\")) * 100, 2)) \\\n",
    "                             .orderBy(desc(\"perc_outliers\"))\n",
    "\n",
    "df_resumo.show(20)\n",
    "\n",
    "# ==============================================================================\n",
    "# PARTE B: TOP 10 MAIS DISCREPANTES POR CLUSTER (Arquivo CSV)\n",
    "# ==============================================================================\n",
    "print(\"--- 3. Extraindo os Top 10 Casos Graves por Cluster ---\")\n",
    "\n",
    "# Definimos uma \"Janela\" por cluster, ordenando pelo valor mais alto (mais grave)\n",
    "janela_cluster = Window.partitionBy(\"prediction\").orderBy(col(\"valor_transacao\").desc())\n",
    "\n",
    "# Criamos um Ranking (1¬∫, 2¬∫, 3¬∫...) e filtramos s√≥ at√© o 10¬∫\n",
    "df_top10 = df_outliers_raw.withColumn(\"rank\", row_number().over(janela_cluster)) \\\n",
    "                          .filter(col(\"rank\") <= 10)\n",
    "\n",
    "# Calculamos m√©tricas finais para o relat√≥rio\n",
    "df_export = df_top10.withColumn(\n",
    "    \"diferenca_valor\", \n",
    "    col(\"valor_transacao\") - col(\"Mediana\")\n",
    ").withColumn(\n",
    "    \"x_vezes_mediana\", \n",
    "    round(col(\"valor_transacao\") / col(\"Mediana\"), 1)\n",
    ").select(\n",
    "    col(\"prediction\").alias(\"Cluster\"),\n",
    "    col(\"rank\").alias(\"Ranking_Gravidade\"),\n",
    "    col(\"objeto_aquisicao\").alias(\"Descricao_Item\"),\n",
    "    col(\"valor_transacao\").alias(\"Preco_Pago\"),\n",
    "    col(\"Mediana\").alias(\"Preco_Medio_Cluster\"),\n",
    "    col(\"limite_superior\").alias(\"Teto_Aceitavel\"),\n",
    "    col(\"x_vezes_mediana\").alias(\"Quantas_Vezes_Mais_Caro\"),\n",
    "    col(\"total_itens_cluster\").alias(\"Tamanho_Cluster\")\n",
    ").orderBy(\"Cluster\", \"Ranking_Gravidade\")\n",
    "\n",
    "# --- Exporta√ß√£o ---\n",
    "try:\n",
    "    pdf_top10 = df_export.toPandas()\n",
    "    nome_arquivo = \"relatorio_top10_outliers.csv\"\n",
    "    \n",
    "    # Salva com encoding correto para Excel/PT-BR\n",
    "    pdf_top10.to_csv(nome_arquivo, index=False, sep=';', encoding='utf-8-sig', float_format='%.2f')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Arquivo '{nome_arquivo}' gerado com sucesso!\")\n",
    "    print(f\"   Conte√∫do: Os 10 maiores desvios de cada um dos clusters.\")\n",
    "    print(f\"   Local: {os.getcwd()}/{nome_arquivo}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao exportar: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6eb55aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Auditoria Preditiva (Random Forest) ---\n",
      "Par√¢metros: Trees=50 | Depth=8 | MinInstances=5 | Target=Log(Preco)\n",
      "‚è≥ Treinando o modelo (analisando padr√µes globais)...\n",
      "üö© O modelo encontrou 1601 transa√ß√µes suspeitas.\n",
      "\n",
      "--- Gerando Arquivo de Auditoria ML ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\VSCode\\projetoMineracao\\venv\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:111: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 4.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivo gerado: 'auditoria_ml_random_forest.csv'\n",
      "\n",
      "--- Top 5 Discrep√¢ncias (Vis√£o do Rob√¥) ---\n",
      "                                      Descricao_Item  Preco_Pago_Real  \\\n",
      "0                                      anel superior     1.015300e+09   \n",
      "1  confeccao de resinas para carimbos material ut...     2.016800e+09   \n",
      "2                                         chapa zn 0     8.040020e+07   \n",
      "3           aquisicao de de dois numeros em aco inox     2.116025e+07   \n",
      "4                       valvula reversora para split     7.300000e+05   \n",
      "\n",
      "   Preco_Justo_Estimado  Quantas_Vezes_Mais_Caro  \n",
      "0                527.95                1923045.8  \n",
      "1               1228.10                1642200.6  \n",
      "2                213.24                 377030.1  \n",
      "3                245.20                  86292.7  \n",
      "4                217.24                   3360.2  \n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA 11 (CORRIGIDA): Auditoria ML (Random Forest Regressor)\n",
    "# ==============================================================================\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.sql.functions import col, log, exp, abs as spark_abs, round, desc\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"--- Iniciando Auditoria Preditiva (Random Forest) ---\")\n",
    "print(f\"Par√¢metros: Trees=50 | Depth=8 | MinInstances=5 | Target=Log(Preco)\")\n",
    "\n",
    "# 1. PREPARA√á√ÉO (CORRE√á√ÉO AQUI: Usamos df_clustered em vez de df_tfidf)\n",
    "# Assim garantimos que a coluna 'prediction' (Cluster ID) exista para o relat√≥rio final.\n",
    "df_ml = df_clustered.withColumn(\"label\", log(col(\"valor_transacao\") + 1.0))\n",
    "\n",
    "# 2. TREINAMENTO DO MODELO\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction_log\", # Nome exclusivo para n√£o conflitar com o cluster\n",
    "    seed=42,\n",
    "    numTrees=50,\n",
    "    maxDepth=8,\n",
    "    minInstancesPerNode=5\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Treinando o modelo (analisando padr√µes globais)...\")\n",
    "model_rf = rf.fit(df_ml)\n",
    "\n",
    "# 3. PREDI√á√ÉO\n",
    "predictions = model_rf.transform(df_ml)\n",
    "\n",
    "# 4. C√ÅLCULO DE DISCREP√ÇNCIA\n",
    "df_analise_ml = predictions.withColumn(\"preco_estimado_ml\", exp(col(\"prediction_log\")) - 1.0) \\\n",
    "                           .withColumn(\"razao_sobrepreco\", col(\"valor_transacao\") / (col(\"preco_estimado_ml\") + 0.01)) \\\n",
    "                           .withColumn(\"diferenca_valor\", col(\"valor_transacao\") - col(\"preco_estimado_ml\"))\n",
    "\n",
    "# 5. FILTRAGEM\n",
    "# Regra: Pre√ßo pago > 3x o estimado E Diferen√ßa > R$ 50\n",
    "df_suspeitas_ml = df_analise_ml.filter((col(\"razao_sobrepreco\") > 3) & \n",
    "                                       (col(\"diferenca_valor\") > 50))\n",
    "\n",
    "# Sele√ß√£o de colunas (Agora 'prediction' vai funcionar pois veio do df_clustered)\n",
    "df_export_ml = df_suspeitas_ml.select(\n",
    "    col(\"prediction\").alias(\"Cluster_Original\"), # <-- Agora esta coluna existe!\n",
    "    col(\"objeto_aquisicao\").alias(\"Descricao_Item\"),\n",
    "    col(\"valor_transacao\").alias(\"Preco_Pago_Real\"),\n",
    "    round(col(\"preco_estimado_ml\"), 2).alias(\"Preco_Justo_Estimado\"),\n",
    "    round(col(\"razao_sobrepreco\"), 1).alias(\"Quantas_Vezes_Mais_Caro\"),\n",
    "    col(\"ano\"),\n",
    "    col(\"unidade_gestora\")\n",
    ").orderBy(desc(\"razao_sobrepreco\"))\n",
    "\n",
    "total_suspeitas = df_export_ml.count()\n",
    "print(f\"üö© O modelo encontrou {total_suspeitas} transa√ß√µes suspeitas.\")\n",
    "\n",
    "# --- 6. EXPORTA√á√ÉO ---\n",
    "print(\"\\n--- Gerando Arquivo de Auditoria ML ---\")\n",
    "\n",
    "try:\n",
    "    pdf_ml = df_export_ml.toPandas()\n",
    "    nome_arquivo_ml = \"auditoria_ml_random_forest.csv\"\n",
    "    \n",
    "    pdf_ml.to_csv(nome_arquivo_ml, index=False, sep=';', encoding='utf-8-sig', float_format='%.2f')\n",
    "    \n",
    "    print(f\"‚úÖ Arquivo gerado: '{nome_arquivo_ml}'\")\n",
    "    \n",
    "    print(\"\\n--- Top 5 Discrep√¢ncias (Vis√£o do Rob√¥) ---\")\n",
    "    print(pdf_ml.head(5)[[\"Descricao_Item\", \"Preco_Pago_Real\", \"Preco_Justo_Estimado\", \"Quantas_Vezes_Mais_Caro\"]])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na exporta√ß√£o: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40ba8fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Cruzamento de Auditorias (Filtro: Score > 10) ---\n",
      "üìÇ Entradas: IQR (1040 linhas) | ML (1601 linhas)\n",
      "üö© Registros Cr√≠ticos (Score > 10): 166\n",
      "\n",
      "‚úÖ Relat√≥rio Cr√≠tico Gerado: 'auditoria_critica_score_10.csv'\n",
      "   Local: c:\\VSCode\\projetoMineracao/auditoria_critica_score_10.csv\n",
      "\n",
      "--- TOP 10 CASOS MAIS GRAVES (ALERTA VERMELHO) ---\n",
      "                                                                                                                                             Descricao_Item   Preco_Pago  Score_Risco  Quantas_Vezes_Mais_Caro\n",
      "confeccao de resinas para carimbos material utilizado para atender as necessidades do protocolo obs a nota fiscal foi preenchida sem a data de emissao logo 2016800184.0 7522083.5184                1642200.6\n",
      "                                                                                                                                              anel superior 1015300400.0 6879356.2474                1923045.8\n",
      "                                                                                                                                                 chapa zn 0   80400200.0  819323.0817                 377030.1\n",
      "                                                                                                                   aquisicao de de dois numeros em aco inox   21160252.0  202697.5312                  86292.7\n",
      "                                                                                                                               valvula reversora para split     730000.0    5571.3212                   3360.2\n",
      "                                                                                                                                                   rebite 3     210500.0    3792.7932                   2635.8\n",
      "                                                                                                             5o laminas em digital e 100 laminas em digital     210297.0    1845.0664                   1319.6\n",
      "                                                                                                                                  joelho de pvc para esgoto      90100.0    1768.3834                   1283.8\n",
      "                                                                                                                               360 tubo soldado 50 mm krona      49050.0    1006.4492                    743.1\n",
      "                                                                                                                            anel de borracha cano de esgoto      10022.0     273.3236                    225.4\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA DE CONSOLIDA√á√ÉO (V2): Cruzamento IQR x ML (Filtro Risco > 10)\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"--- Iniciando Cruzamento de Auditorias (Filtro: Score > 10) ---\")\n",
    "\n",
    "# Defini√ß√£o dos arquivos de entrada\n",
    "file_iqr = \"auditoria_outliers_iqr.csv\"\n",
    "file_ml = \"auditoria_ml_random_forest.csv\"\n",
    "\n",
    "# Verifica√ß√£o de exist√™ncia\n",
    "if not os.path.exists(file_iqr) or not os.path.exists(file_ml):\n",
    "    print(\"‚ùå Erro: Um dos arquivos de entrada n√£o foi encontrado.\")\n",
    "    print(\"   Certifique-se de ter rodado a C√©lula 10 (IQR) e a C√©lula 11 (ML).\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. Carregar os Relat√≥rios\n",
    "        # Usamos float_precision='high' para garantir precis√£o nos valores monet√°rios\n",
    "        df_iqr = pd.read_csv(file_iqr, sep=';', encoding='utf-8-sig')\n",
    "        df_ml = pd.read_csv(file_ml, sep=';', encoding='utf-8-sig')\n",
    "\n",
    "        print(f\"üìÇ Entradas: IQR ({len(df_iqr)} linhas) | ML ({len(df_ml)} linhas)\")\n",
    "\n",
    "        # 2. Padroniza√ß√£o\n",
    "        df_ml.rename(columns={'Preco_Pago_Real': 'Preco_Pago'}, inplace=True)\n",
    "\n",
    "        # 3. O Cruzamento (Interse√ß√£o)\n",
    "        # Identificamos os itens que aparecem nos DOIS relat√≥rios\n",
    "        df_consenso = pd.merge(\n",
    "            df_iqr, \n",
    "            df_ml, \n",
    "            on=['Descricao_Item', 'Preco_Pago', 'ano', 'unidade_gestora'],\n",
    "            how='inner',\n",
    "            suffixes=('_IQR', '_ML')\n",
    "        )\n",
    "        \n",
    "        # 4. C√°lculo do Score de Risco Unificado\n",
    "        # F√≥rmula: (Vezes mais caro ML) + (Excesso IQR / 100)\n",
    "        # Ex: Se ML diz que √© 10x mais caro e IQR diz que estourou 500% o teto -> Score = 10 + 5 = 15\n",
    "        df_consenso['Score_Risco'] = df_consenso['Quantas_Vezes_Mais_Caro'] + (df_consenso['Perc_Excesso'] / 100)\n",
    "        \n",
    "        # 5. FILTRAGEM AGRESSIVA (Score > 10)\n",
    "        # S√≥ passamos para o arquivo final se o risco for alt√≠ssimo\n",
    "        df_final = df_consenso[df_consenso['Score_Risco'] > 10].copy()\n",
    "        \n",
    "        # Organiza√ß√£o das Colunas\n",
    "        colunas_finais = [\n",
    "            'Cluster_ID',              \n",
    "            'Descricao_Item',          \n",
    "            'Preco_Pago',              \n",
    "            'Score_Risco',             \n",
    "            'Preco_Justo_Estimado',    # Vis√£o ML\n",
    "            'Teto_Estatistico',        # Vis√£o Estat√≠stica\n",
    "            'Quantas_Vezes_Mais_Caro', # Indicador ML\n",
    "            'Perc_Excesso',            # Indicador IQR\n",
    "            'ano',\n",
    "            'unidade_gestora'\n",
    "        ]\n",
    "        \n",
    "        # Ordena: O maior risco no topo\n",
    "        df_final = df_final[colunas_finais].sort_values(by='Score_Risco', ascending=False)\n",
    "        \n",
    "        qtd_total = len(df_final)\n",
    "        print(f\"üö© Registros Cr√≠ticos (Score > 10): {qtd_total}\")\n",
    "\n",
    "        # 6. Exporta√ß√£o\n",
    "        nome_arquivo_final = \"auditoria_critica_score_10.csv\"\n",
    "        \n",
    "        if qtd_total > 0:\n",
    "            df_final.to_csv(nome_arquivo_final, index=False, sep=';', encoding='utf-8-sig', float_format='%.2f')\n",
    "            print(f\"\\n‚úÖ Relat√≥rio Cr√≠tico Gerado: '{nome_arquivo_final}'\")\n",
    "            print(f\"   Local: {os.getcwd()}/{nome_arquivo_final}\")\n",
    "            \n",
    "            print(\"\\n--- TOP 10 CASOS MAIS GRAVES (ALERTA VERMELHO) ---\")\n",
    "            display_cols = ['Descricao_Item', 'Preco_Pago', 'Score_Risco', 'Quantas_Vezes_Mais_Caro']\n",
    "            # Formata√ß√£o para leitura no console\n",
    "            print(df_final[display_cols].head(10).to_string(index=False))\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è Nenhum registro superou o Score de Risco > 10.\")\n",
    "            print(\"   Isso significa que, embora existam outliers, nenhum √© t√£o extremo a ponto de cruzar os dois m√©todos com essa intensidade.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro durante o processamento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e5a2007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Enriquecimento dos Dados (Recuperando CPFs e Favorecidos) ---\n",
      "üìÇ Carregados 166 registros cr√≠ticos para enriquecimento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\VSCode\\projetoMineracao\\venv\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:351: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 4.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warn(msg)\n",
      "c:\\VSCode\\projetoMineracao\\venv\\Lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:111: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 4.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Relat√≥rio Completo Gerado: 'AUDITORIA_COMPLETA_RASTREAVEL.csv'\n",
      "   Conte√∫do: 94 linhas com dados cadastrais completos.\n",
      "   Local: c:\\VSCode\\projetoMineracao/AUDITORIA_COMPLETA_RASTREAVEL.csv\n",
      "\n",
      "--- Exemplo de Registro Completo (Top 1) ---\n",
      "                                                                        0\n",
      "Score_Risco                                                         82.01\n",
      "Fator_Sobrepreco                                                     59.3\n",
      "Perc_Acima_Teto_Cluster                                           2271.33\n",
      "Preco_Ref_ML                                                        74.16\n",
      "Preco_Ref_Cluster                                                  185.55\n",
      "Descricao_Original       compra emergencial para enfermagem mascara caixa\n",
      "Valor_Pago                                                         4400.0\n",
      "data_aquisicao                                                 17/09/2020\n",
      "ano                                                                  2020\n",
      "unidade_gestora                                                       pgr\n",
      "Cluster_ID                                                             12\n",
      "Nome_Suprido                                          antonia rosa vieira\n",
      "CPF_Suprido                                                   31369502168\n",
      "Nome_Favorecido              emedf comercio de produtos odontologicos epp\n",
      "CNPJ_Favorecido                                            01686183000103\n",
      "periodo_aplicacao                                 10/09/2020 a 13/11/2020\n",
      "aprovado                                                              sim\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# C√âLULA FINAL (CORRIGIDA): Enriquecimento (Join com Dados Originais)\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"--- Iniciando Enriquecimento dos Dados (Recuperando CPFs e Favorecidos) ---\")\n",
    "\n",
    "# Arquivo de entrada\n",
    "file_critico = \"auditoria_critica_score_10.csv\"\n",
    "\n",
    "if not os.path.exists(file_critico):\n",
    "    print(f\"‚ùå Erro: O arquivo '{file_critico}' n√£o foi encontrado.\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. Carregar as Anomalias (Pandas)\n",
    "        pdf_criticos = pd.read_csv(file_critico, sep=';', encoding='utf-8-sig')\n",
    "        qtd_criticos = len(pdf_criticos)\n",
    "        print(f\"üìÇ Carregados {qtd_criticos} registros cr√≠ticos para enriquecimento.\")\n",
    "\n",
    "        if qtd_criticos > 0:\n",
    "            # 2. Sele√ß√£o e Renomea√ß√£o (CORRIGIDO)\n",
    "            \n",
    "            # Lista das colunas que existem no CSV\n",
    "            cols_csv = ['Descricao_Item', 'Preco_Pago', 'ano', 'unidade_gestora', \n",
    "                        'Score_Risco', 'Preco_Justo_Estimado', 'Teto_Estatistico', \n",
    "                        'Quantas_Vezes_Mais_Caro', 'Perc_Excesso']\n",
    "            \n",
    "            # Filtramos o PDF apenas com essas colunas\n",
    "            pdf_filtrado = pdf_criticos[cols_csv].copy()\n",
    "            \n",
    "            # Agora renomeamos para bater com os nomes do Spark (df_clustered)\n",
    "            pdf_renomeado = pdf_filtrado.rename(columns={\n",
    "                'Descricao_Item': 'objeto_aquisicao', \n",
    "                'Preco_Pago': 'valor_transacao'\n",
    "            })\n",
    "            \n",
    "            # 3. Cria√ß√£o do DataFrame Spark (Chaves para o Join)\n",
    "            # O Spark vai receber 'objeto_aquisicao' e 'valor_transacao' corretamente agora\n",
    "            df_keys = spark.createDataFrame(pdf_renomeado)\n",
    "\n",
    "            # 4. O JOIN (Recuperando os dados originais)\n",
    "            # Fazemos o join usando as colunas renomeadas\n",
    "            df_completo = df_clustered.join(\n",
    "                df_keys,\n",
    "                on=['objeto_aquisicao', 'valor_transacao', 'ano', 'unidade_gestora'],\n",
    "                how='inner'\n",
    "            )\n",
    "\n",
    "            # 5. Sele√ß√£o Final para o Relat√≥rio (Organiza√ß√£o)\n",
    "            df_relatorio_final = df_completo.select(\n",
    "                # M√©tricas de Auditoria\n",
    "                col(\"Score_Risco\"),\n",
    "                col(\"Quantas_Vezes_Mais_Caro\").alias(\"Fator_Sobrepreco\"),\n",
    "                col(\"Perc_Excesso\").alias(\"Perc_Acima_Teto_Cluster\"),\n",
    "                col(\"Preco_Justo_Estimado\").alias(\"Preco_Ref_ML\"),\n",
    "                col(\"Teto_Estatistico\").alias(\"Preco_Ref_Cluster\"),\n",
    "                \n",
    "                # Dados da Compra\n",
    "                col(\"objeto_aquisicao\").alias(\"Descricao_Original\"),\n",
    "                col(\"valor_transacao\").alias(\"Valor_Pago\"),\n",
    "                col(\"data_aquisicao\"),\n",
    "                col(\"ano\"),\n",
    "                col(\"unidade_gestora\"),\n",
    "                col(\"prediction\").alias(\"Cluster_ID\"),\n",
    "\n",
    "                # Dados Cadastrais (Ouro)\n",
    "                col(\"nome_suprido\").alias(\"Nome_Suprido\"),\n",
    "                col(\"cpf_suprido\").alias(\"CPF_Suprido\"),\n",
    "                col(\"nome_favorecido\").alias(\"Nome_Favorecido\"),\n",
    "                col(\"cpf_cnpj_favorecido\").alias(\"CNPJ_Favorecido\"),\n",
    "                \n",
    "                col(\"periodo_aplicacao\"),\n",
    "                col(\"aprovado\")\n",
    "            ).orderBy(col(\"Score_Risco\").desc())\n",
    "\n",
    "            # 6. Exporta√ß√£o Final\n",
    "            nome_arquivo_rastreio = \"AUDITORIA_COMPLETA_RASTREAVEL.csv\"\n",
    "            \n",
    "            pdf_final = df_relatorio_final.toPandas()\n",
    "            pdf_final.to_csv(nome_arquivo_rastreio, index=False, sep=';', encoding='utf-8-sig', float_format='%.2f')\n",
    "\n",
    "            print(f\"\\n‚úÖ Relat√≥rio Completo Gerado: '{nome_arquivo_rastreio}'\")\n",
    "            print(f\"   Conte√∫do: {len(pdf_final)} linhas com dados cadastrais completos.\")\n",
    "            print(f\"   Local: {os.getcwd()}/{nome_arquivo_rastreio}\")\n",
    "            \n",
    "            print(\"\\n--- Exemplo de Registro Completo (Top 1) ---\")\n",
    "            print(pdf_final.head(1).T)\n",
    "\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è N√£o h√° registros cr√≠ticos para enriquecer.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro no enriquecimento: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
