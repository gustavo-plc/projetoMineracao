import os

# ==============================================================================
# Gerador de Documenta√ß√£o T√©cnica - Projeto Minera√ß√£o de Gastos P√∫blicos
# Vers√£o: Fase 2 (Minera√ß√£o de Dados, NLP e Machine Learning)
# ==============================================================================

conteudo_docs_fase2 = """# üìò Manual T√©cnico Unificado: Fase 2 - Minera√ß√£o e Auditoria Avan√ßada

**Projeto:** Minera√ß√£o e Auditoria de Cart√£o Corporativo (CPGF)
**Status:** Fase 2 Conclu√≠da (NLP, Clusteriza√ß√£o e Detec√ß√£o H√≠brida de Anomalias)
**Tecnologia:** Python 3.x + PySpark MLlib (Local/Windows)
**Vers√£o do Pipeline:** 2.0 (Consenso Estat√≠stico + Supervisionado)

---

## 1. Vis√£o Geral e Arquitetura

A Fase 2 foca na transforma√ß√£o de dados textuais em intelig√™ncia audit√°vel. O pipeline abandona a an√°lise puramente descritiva para adotar modelos preditivos e estat√≠sticos que identificam sobrepre√ßo baseados em **sem√¢ntica** (o que √© o item) e **contexto** (em qual grupo ele se encaixa).

### Fluxo de Processamento (Pipeline ML)
1.  **Saneamento:** Remo√ß√£o de duplicatas estritas para garantir integridade.
2.  **NLP Cir√∫rgico:** Limpeza de "juridiqu√™s" para isolar o objeto real da compra.
3.  **Vetoriza√ß√£o:** Transforma√ß√£o de texto em matem√°tica (`Word2Vec`).
4.  **Clusteriza√ß√£o:** Agrupamento tem√°tico (`Bisecting K-Means`).
5.  **Auditoria Paralela:**
    * *M√©todo A:* Estat√≠stica Intra-Cluster (`IQR/Boxplot`).
    * *M√©todo B:* Intelig√™ncia Artificial Global (`Random Forest Regressor`).
6.  **Consenso e Enriquecimento:** Cruzamento dos m√©todos e recupera√ß√£o de dados cadastrais (CPF/CNPJ).

---

## 2. Detalhamento T√©cnico dos Componentes

### 2.1. Pr√©-Processamento e NLP (Limpeza Sem√¢ntica)
O objetivo √© remover ru√≠do burocr√°tico para que o algoritmo foque no produto f√≠sico.

* **Biblioteca:** `pyspark.ml.feature.StopWordsRemover` + Filtros SQL.
* **Entrada:** Texto bruto (ex: "Aquisi√ß√£o emergencial de pneus").
* **Execu√ß√£o:**
    * **Stopwords:** Remo√ß√£o de ~150 termos de processo (`necessidade`, `urgencia`, `vulto`, `solicitado`, `conforme`).
    * **Filtros de Radical (SQL):** Remo√ß√£o agressiva de termos iniciados em `almox*` (almoxarifado), `reemb*` (reembolso), `disponi*` (disponibilidade).
* **Sa√≠da:** Lista de tokens limpa (ex: `['pneus']`).
* **Impacto:** Evita que itens sejam agrupados por serem "urgentes" em vez de serem "pneus".

### 2.2. Vetoriza√ß√£o (Word2Vec)
Ensina o computador a entender contexto e sin√¥nimos.

* **Biblioteca:** `pyspark.ml.feature.Word2Vec`
* **Par√¢metros Cr√≠ticos:**
    * `vectorSize`: **50** (Dimens√£o do vetor. Equil√≠brio entre nuance e performance).
    * `minCount`: **5** (Filtro de qualidade. Ignora palavras que aparecem < 5 vezes, eliminando "typos" e marcas raras).
    * `windowSize`: **2** (Contexto curto).
* **Entrada:** Lista de tokens filtrada.
* **Sa√≠da:** Vetor Denso (`raw_features`) + Normaliza√ß√£o L2 (`features`).

### 2.3. Clusteriza√ß√£o (Bisecting K-Means)
Cria√ß√£o de "gavetas" tem√°ticas para compara√ß√£o justa de pre√ßos.

* **Biblioteca:** `pyspark.ml.clustering.BisectingKMeans`
* **Par√¢metros:**
    * `k`: **20** (N√∫mero de grupos final).
    * `distanceMeasure`: **"cosine"** (Mede similaridade sem√¢ntica pelo √¢ngulo, n√£o dist√¢ncia f√≠sica).
    * `minDivisibleClusterSize`: **100**.
* **Sa√≠da:** Coluna `prediction` (ID do Cluster, 0 a 19).
* **L√≥gica:** Algoritmo hier√°rquico (divisivo). Separa macro-temas (ex: "Servi√ßos" vs "Produtos") e depois micro-temas ("Pe√ßas de Carro" vs "Material de Constru√ß√£o").

---

## 3. Metodologia de Detec√ß√£o de Anomalias (O "C√©rebro" da Auditoria)

Utilizamos uma abordagem h√≠brida para reduzir falsos positivos. Um item s√≥ √© considerado cr√≠tico se falhar em m√∫ltiplos testes ou tiver score de risco alt√≠ssimo.

### M√©todo 1: Estat√≠stica Intra-Cluster (IQR)
Analisa o item em rela√ß√£o aos seus "vizinhos" de grupo.
* **T√©cnica:** Intervalo Interquartil (Boxplot).
* **C√°lculo:**
    * Teto = $Q3 + 1.5 \\times (Q3 - Q1)$
* **Gatilho:** Valor > Teto **E** Valor > R$ 50,00.
* **Ponto Forte:** Detecta o "ponto fora da curva" √≥bvio (ex: uma caneta de R$ 500 no cluster de papelaria).
* **Ponto Fraco:** Cego se o cluster inteiro estiver contaminado.

### M√©todo 2: Predi√ß√£o Supervisionada (Random Forest)
Analisa o item em rela√ß√£o ao "conhecimento global" da base.
* **Biblioteca:** `pyspark.ml.regression.RandomForestRegressor`.
* **Target:** `Log(Pre√ßo)` (Reduz distor√ß√£o de valores bilion√°rios).
* **Par√¢metros:**
    * `numTrees`: **50** (√Årvores de decis√£o independentes).
    * `maxDepth`: **8** (Evita overfitting/decorar compras espec√≠ficas).
    * `minInstancesPerNode`: **5** (Exige repeti√ß√£o do padr√£o para validar a regra).
* **Execu√ß√£o:** O modelo prev√™ quanto o item *deveria* custar baseado no texto.
* **Gatilho:** Pre√ßo Pago > 3x Pre√ßo Estimado.
* **Ponto Forte:** Detecta erros de classifica√ß√£o (ex: um parafuso que caiu no cluster de carros por engano ser√° pego aqui, pois o texto diz "parafuso").

---

## 4. Consolida√ß√£o e Score de Risco

A etapa final cruza os dois m√©todos para gerar a "Lista de Ouro" da auditoria.

### 4.1. F√≥rmula de Risco
O Score unifica a gravidade das duas detec√ß√µes:
$$Score = (Fator\_ML) + \\frac{Excesso\_IQR(\%)}{100}$$

* *Exemplo:* Um item custou 10x o estimado pelo rob√¥ (ML) e furou o teto do cluster em 500% (IQR).
    * Score = 10 + 5 = **15**.

### 4.2. Filtro de Corte (Threshold)
* **Regra:** `Score_Risco > 10`.
* **Objetivo:** Isolar apenas as anomalias indefens√°veis para a auditoria manual.

### 4.3. Enriquecimento (Rastreabilidade)
O script final realiza um *Join* reverso com o Dataset Original para recuperar:
* **Quem comprou:** `unidade_gestora`, `cpf_suprido`, `nome_suprido`.
* **Quem recebeu:** `nome_favorecido`, `cpf_cnpj_favorecido`.
* **Quando:** `data_aquisicao`.

---

## 5. Dicion√°rio de Sa√≠das (Artifacts)

| Arquivo Gerado | Descri√ß√£o | Uso Principal |
| :--- | :--- | :--- |
| `relatorio_outliers_iqr.csv` | Todas as anomalias estat√≠sticas por cluster. | An√°lise de dispers√£o de pre√ßos dentro dos grupos. |
| `auditoria_ml_random_forest.csv` | Todas as discrep√¢ncias Texto vs. Pre√ßo. | Identificar itens caros mal classificados. |
| `AUDITORIA_COMPLETA_RASTREAVEL.csv` | **Relat√≥rio Final**. Cruzamento ML + IQR com dados cadastrais. | **Auditoria e Investiga√ß√£o**. Cont√©m o Score de Risco. |

---

## 6. Como Executar (Fase 2)

1.  **Pr√©-requisito:** Ter o arquivo `Consolidado_Final` gerado na Fase 1.
2.  **Execu√ß√£o:** Rodar o notebook/script `analise_fase2.py` sequencialmente.
3.  **Monitoramento:** Acompanhar os logs de calibra√ß√£o do Random Forest (RMSE).
4.  **Resultado:** Abrir o arquivo `AUDITORIA_COMPLETA_RASTREAVEL.csv` no Excel (separador `;`, UTF-8) e ordenar pela coluna `Score_Risco`.

"""

# Define o caminho para salvar o arquivo na pasta atual do projeto
nome_arquivo = "Documentacao_Tecnica_Auditoria_Fase2.md"
caminho_completo = os.path.join(os.getcwd(), nome_arquivo)

try:
    with open(caminho_completo, "w", encoding="utf-8") as f:
        f.write(conteudo_docs_fase2)
    print(f"‚úÖ Documenta√ß√£o da Fase 2 gerada com sucesso!")
    print(f"üìÇ Arquivo: {caminho_completo}")
    print("   (Abrange NLP, Clusteriza√ß√£o, Random Forest e F√≥rmula de Risco)")
except Exception as e:
    print(f"‚ùå Erro ao gerar documenta√ß√£o: {e}")